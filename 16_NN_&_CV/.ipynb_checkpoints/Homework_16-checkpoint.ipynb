{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "accepted-energy",
   "metadata": {},
   "source": [
    "# Homework - Neural Networks & Computer Vision\n",
    "\n",
    "***Agata Makarewicz***\n",
    "\n",
    "*Week 16*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-plaza",
   "metadata": {},
   "source": [
    "## 0. Introduction\n",
    "\n",
    "Task: two parts - basic and CV\n",
    "\n",
    "Basic part - solving regression and classification tasks with usage of simple neural networks. \\\n",
    "CV part - implementing binary classification which should classify images in 2 classes - hot dog or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "danish-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"darkgrid\")\n",
    "\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "plotly.io.renderers.default = 'colab'\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit, train_test_split, GridSearchCV, TimeSeriesSplit\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, f1_score, fbeta_score, classification_report\n",
    "from sklearn.metrics import plot_confusion_matrix, precision_score, recall_score, precision_recall_curve\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils, datasets\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (9, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-february",
   "metadata": {},
   "source": [
    "## I. Basic part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "numerous-blade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression\n",
    "data_regr = pd.read_table('AirQualityUCI.csv', sep = ';', na_values=-200, decimal = ',')\n",
    "target_regr = \"C6H6(GT)\"\n",
    "# classification\n",
    "data_classif = pd.read_csv('dataset_57_hypothyroid.csv', na_values=\"?\")\n",
    "target_classif = \"Class\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-bouquet",
   "metadata": {},
   "source": [
    "### I.I. Data preprocessing\n",
    "\n",
    "Both datasets have been already used in previous homeworks and EDA was done there, so in this part we will simply use previous solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adopted-savannah",
   "metadata": {},
   "source": [
    "#### I.I.I Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "veterinary-closure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9471, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>CO(GT)</th>\n",
       "      <th>PT08.S1(CO)</th>\n",
       "      <th>NMHC(GT)</th>\n",
       "      <th>C6H6(GT)</th>\n",
       "      <th>PT08.S2(NMHC)</th>\n",
       "      <th>NOx(GT)</th>\n",
       "      <th>PT08.S3(NOx)</th>\n",
       "      <th>NO2(GT)</th>\n",
       "      <th>PT08.S4(NO2)</th>\n",
       "      <th>PT08.S5(O3)</th>\n",
       "      <th>T</th>\n",
       "      <th>RH</th>\n",
       "      <th>AH</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>18.00.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>1046.0</td>\n",
       "      <td>166.0</td>\n",
       "      <td>1056.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>1692.0</td>\n",
       "      <td>1268.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>48.9</td>\n",
       "      <td>0.7578</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>19.00.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1292.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>955.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1174.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>1559.0</td>\n",
       "      <td>972.0</td>\n",
       "      <td>13.3</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>20.00.00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>939.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1140.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1555.0</td>\n",
       "      <td>1074.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.7502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>21.00.00</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1376.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>948.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.7867</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/03/2004</td>\n",
       "      <td>22.00.00</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1272.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>836.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1490.0</td>\n",
       "      <td>1110.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>59.6</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date      Time  CO(GT)  PT08.S1(CO)  NMHC(GT)  C6H6(GT)  \\\n",
       "0  10/03/2004  18.00.00     2.6       1360.0     150.0      11.9   \n",
       "1  10/03/2004  19.00.00     2.0       1292.0     112.0       9.4   \n",
       "2  10/03/2004  20.00.00     2.2       1402.0      88.0       9.0   \n",
       "3  10/03/2004  21.00.00     2.2       1376.0      80.0       9.2   \n",
       "4  10/03/2004  22.00.00     1.6       1272.0      51.0       6.5   \n",
       "\n",
       "   PT08.S2(NMHC)  NOx(GT)  PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)  \\\n",
       "0         1046.0    166.0        1056.0    113.0        1692.0       1268.0   \n",
       "1          955.0    103.0        1174.0     92.0        1559.0        972.0   \n",
       "2          939.0    131.0        1140.0    114.0        1555.0       1074.0   \n",
       "3          948.0    172.0        1092.0    122.0        1584.0       1203.0   \n",
       "4          836.0    131.0        1205.0    116.0        1490.0       1110.0   \n",
       "\n",
       "      T    RH      AH  Unnamed: 15  Unnamed: 16  \n",
       "0  13.6  48.9  0.7578          NaN          NaN  \n",
       "1  13.3  47.7  0.7255          NaN          NaN  \n",
       "2  11.9  54.0  0.7502          NaN          NaN  \n",
       "3  11.0  60.0  0.7867          NaN          NaN  \n",
       "4  11.2  59.6  0.7888          NaN          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_regr.shape)\n",
    "data_regr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "democratic-resource",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_regr[target_regr].isna().sum() # missing values in target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "shaped-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_regr = data_regr.drop(['Unnamed: 15', 'Unnamed: 16'], axis=1) # NaN columns created due to two unnecessary \";\" after last column name\n",
    "nan_rows = data_regr[data_regr.shape[1] - data_regr.count(axis=1) == 15].index # NaN rows introduced at the end of the file\n",
    "data_regr = data_regr.drop(nan_rows, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adequate-atlas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8983, 14)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_regr = data_regr.drop('NMHC(GT)', axis=1) # column with 90% NA\n",
    "data_regr = data_regr.dropna(subset=['PT08.S1(CO)']) # 366 rows with missing in many columns, also target\n",
    "data_regr = data_regr.loc[(data_regr[target_regr] < 60) & (data_regr['PT08.S3(NOx)'] < 2200 )].reset_index(drop=True) # outliers\n",
    "data_regr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "smooth-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date & time column converted to datetime and set as index\n",
    "data_regr.Time = data_regr.Time.str.replace('.',':')\n",
    "data_regr.Date = data_regr[\"Date\"] + ' ' + data_regr[\"Time\"]\n",
    "data_regr.Date = pd.to_datetime(data_regr.Date)\n",
    "data_regr = data_regr.set_index('Date')\n",
    "data_regr.drop(['Time'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "vietnamese-devices",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 8983 entries, 2004-10-03 18:00:00 to 2005-04-04 14:00:00\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   CO(GT)         7337 non-null   float64\n",
      " 1   PT08.S1(CO)    8983 non-null   float64\n",
      " 2   C6H6(GT)       8983 non-null   float64\n",
      " 3   PT08.S2(NMHC)  8983 non-null   float64\n",
      " 4   NOx(GT)        7388 non-null   float64\n",
      " 5   PT08.S3(NOx)   8983 non-null   float64\n",
      " 6   NO2(GT)        7385 non-null   float64\n",
      " 7   PT08.S4(NO2)   8983 non-null   float64\n",
      " 8   PT08.S5(O3)    8983 non-null   float64\n",
      " 9   T              8983 non-null   float64\n",
      " 10  RH             8983 non-null   float64\n",
      " 11  AH             8983 non-null   float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 912.3 KB\n"
     ]
    }
   ],
   "source": [
    "data_regr.info() # only numeric variables - no need to encode any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sunset-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputation & normalization\n",
    "num_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('variance_trsh', VarianceThreshold(threshold=0.1))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-medium",
   "metadata": {},
   "source": [
    "#### I.I.II Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "whole-calculator",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3772, 30)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>on_thyroxine</th>\n",
       "      <th>query_on_thyroxine</th>\n",
       "      <th>on_antithyroid_medication</th>\n",
       "      <th>sick</th>\n",
       "      <th>pregnant</th>\n",
       "      <th>thyroid_surgery</th>\n",
       "      <th>I131_treatment</th>\n",
       "      <th>query_hypothyroid</th>\n",
       "      <th>query_hyperthyroid</th>\n",
       "      <th>lithium</th>\n",
       "      <th>goitre</th>\n",
       "      <th>tumor</th>\n",
       "      <th>hypopituitary</th>\n",
       "      <th>psych</th>\n",
       "      <th>TSH_measured</th>\n",
       "      <th>TSH</th>\n",
       "      <th>T3_measured</th>\n",
       "      <th>T3</th>\n",
       "      <th>TT4_measured</th>\n",
       "      <th>TT4</th>\n",
       "      <th>T4U_measured</th>\n",
       "      <th>T4U</th>\n",
       "      <th>FTI_measured</th>\n",
       "      <th>FTI</th>\n",
       "      <th>TBG_measured</th>\n",
       "      <th>TBG</th>\n",
       "      <th>referral_source</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41.0</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>1.30</td>\n",
       "      <td>t</td>\n",
       "      <td>2.5</td>\n",
       "      <td>t</td>\n",
       "      <td>125.0</td>\n",
       "      <td>t</td>\n",
       "      <td>1.14</td>\n",
       "      <td>t</td>\n",
       "      <td>109.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SVHC</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>4.10</td>\n",
       "      <td>t</td>\n",
       "      <td>2.0</td>\n",
       "      <td>t</td>\n",
       "      <td>102.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46.0</td>\n",
       "      <td>M</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>0.98</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>t</td>\n",
       "      <td>109.0</td>\n",
       "      <td>t</td>\n",
       "      <td>0.91</td>\n",
       "      <td>t</td>\n",
       "      <td>120.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.0</td>\n",
       "      <td>F</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>0.16</td>\n",
       "      <td>t</td>\n",
       "      <td>1.9</td>\n",
       "      <td>t</td>\n",
       "      <td>175.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>other</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.0</td>\n",
       "      <td>F</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>0.72</td>\n",
       "      <td>t</td>\n",
       "      <td>1.2</td>\n",
       "      <td>t</td>\n",
       "      <td>61.0</td>\n",
       "      <td>t</td>\n",
       "      <td>0.87</td>\n",
       "      <td>t</td>\n",
       "      <td>70.0</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SVI</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age sex on_thyroxine query_on_thyroxine on_antithyroid_medication sick  \\\n",
       "0  41.0   F            f                  f                         f    f   \n",
       "1  23.0   F            f                  f                         f    f   \n",
       "2  46.0   M            f                  f                         f    f   \n",
       "3  70.0   F            t                  f                         f    f   \n",
       "4  70.0   F            f                  f                         f    f   \n",
       "\n",
       "  pregnant thyroid_surgery I131_treatment query_hypothyroid  \\\n",
       "0        f               f              f                 f   \n",
       "1        f               f              f                 f   \n",
       "2        f               f              f                 f   \n",
       "3        f               f              f                 f   \n",
       "4        f               f              f                 f   \n",
       "\n",
       "  query_hyperthyroid lithium goitre tumor hypopituitary psych TSH_measured  \\\n",
       "0                  f       f      f     f             f     f            t   \n",
       "1                  f       f      f     f             f     f            t   \n",
       "2                  f       f      f     f             f     f            t   \n",
       "3                  f       f      f     f             f     f            t   \n",
       "4                  f       f      f     f             f     f            t   \n",
       "\n",
       "    TSH T3_measured   T3 TT4_measured    TT4 T4U_measured   T4U FTI_measured  \\\n",
       "0  1.30           t  2.5            t  125.0            t  1.14            t   \n",
       "1  4.10           t  2.0            t  102.0            f   NaN            f   \n",
       "2  0.98           f  NaN            t  109.0            t  0.91            t   \n",
       "3  0.16           t  1.9            t  175.0            f   NaN            f   \n",
       "4  0.72           t  1.2            t   61.0            t  0.87            t   \n",
       "\n",
       "     FTI TBG_measured  TBG referral_source     Class  \n",
       "0  109.0            f  NaN            SVHC  negative  \n",
       "1    NaN            f  NaN           other  negative  \n",
       "2  120.0            f  NaN           other  negative  \n",
       "3    NaN            f  NaN           other  negative  \n",
       "4   70.0            f  NaN             SVI  negative  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data_classif.shape)\n",
    "data_classif.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "express-international",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative                   3481\n",
       "compensated_hypothyroid     194\n",
       "primary_hypothyroid          95\n",
       "secondary_hypothyroid         2\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_classif[target_classif].value_counts() # 4 classes, but one has only 2 occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dirty-tiffany",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_classif = data_classif.drop(data_classif[data_classif[target_classif] == 'secondary_hypothyroid'].index) # 2 records \n",
    "data_classif = data_classif.drop(['TBG','TBG_measured','TSH_measured', 'T3_measured', 'TT4_measured',\n",
    "                                  'T4U_measured', 'FTI_measured'], axis=1) # unimportant columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "outstanding-scale",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_classif.drop(data_classif[data_classif.age > 100].index, inplace = True) # outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "established-protection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3769 entries, 0 to 3771\n",
      "Data columns (total 23 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   age                        3768 non-null   float64\n",
      " 1   sex                        3619 non-null   object \n",
      " 2   on_thyroxine               3769 non-null   object \n",
      " 3   query_on_thyroxine         3769 non-null   object \n",
      " 4   on_antithyroid_medication  3769 non-null   object \n",
      " 5   sick                       3769 non-null   object \n",
      " 6   pregnant                   3769 non-null   object \n",
      " 7   thyroid_surgery            3769 non-null   object \n",
      " 8   I131_treatment             3769 non-null   object \n",
      " 9   query_hypothyroid          3769 non-null   object \n",
      " 10  query_hyperthyroid         3769 non-null   object \n",
      " 11  lithium                    3769 non-null   object \n",
      " 12  goitre                     3769 non-null   object \n",
      " 13  tumor                      3769 non-null   object \n",
      " 14  hypopituitary              3769 non-null   object \n",
      " 15  psych                      3769 non-null   object \n",
      " 16  TSH                        3400 non-null   float64\n",
      " 17  T3                         3000 non-null   float64\n",
      " 18  TT4                        3538 non-null   float64\n",
      " 19  T4U                        3383 non-null   float64\n",
      " 20  FTI                        3385 non-null   float64\n",
      " 21  referral_source            3769 non-null   object \n",
      " 22  Class                      3769 non-null   object \n",
      "dtypes: float64(6), object(17)\n",
      "memory usage: 706.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data_classif.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fourth-stranger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsetting columns to different encoding/imputation\n",
    "one_cols = ['referral_source', 'sex']\n",
    "num_cols = data_classif.select_dtypes('number').columns\n",
    "bin_cols = data_classif.select_dtypes(np.object).columns\n",
    "bin_cols = bin_cols.drop(['referral_source', 'sex', 'Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "christian-heather",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipe_classif = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "bin_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # just in case, no need\n",
    "    ('encoder', OrdinalEncoder()) # will work as binary\n",
    "])\n",
    "\n",
    "one_hot_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    ('encoder', OneHotEncoder())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "reverse-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all transformations at once applied to given columns\n",
    "pipe = ColumnTransformer(transformers=[\n",
    "    ('bin', bin_pipe, bin_cols),\n",
    "    ('num', num_pipe_classif, num_cols),\n",
    "    ('one', one_hot_pipe, one_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "seeing-worthy",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # normalization (to apply after all the encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "former-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just to get column names\n",
    "temp = pipe.fit_transform(data_classif) \n",
    "one_hot_names = pipe.named_transformers_['one']['encoder'].get_feature_names()\n",
    "for i in range(len(one_hot_names)):\n",
    "    one_hot_names[i] = one_hot_names[i].replace('x0','referral_source')\n",
    "    one_hot_names[i] = one_hot_names[i].replace('x1','sex')\n",
    "    \n",
    "classif_column_names = bin_cols.to_list() + num_cols.to_list() + list(one_hot_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compound-physics",
   "metadata": {},
   "source": [
    "### I.II. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "downtown-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics for regression task\n",
    "def evaluate_regr(X_train, X_val, Y_train, Y_val, pred_train, pred_val):\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'MAE': [mean_absolute_error(Y_train, pred_train), mean_absolute_error(Y_val, pred_val)], \n",
    "        'MSE': [mean_squared_error(Y_train, pred_train), mean_squared_error(Y_val, pred_val)],\n",
    "        'RMSE': [np.sqrt(mean_squared_error(Y_train, pred_train)), np.sqrt(mean_squared_error(Y_val, pred_val))],\n",
    "        'R2': [r2_score(Y_train, pred_train), r2_score(Y_val, pred_val)],\n",
    "        'Adj R2': [1 - (1-r2_score(Y_train, pred_train))*(len(Y_train)-1)/(len(Y_train)-X_train.shape[1]-1),\n",
    "                   1 - (1-r2_score(Y_val, pred_val))*(len(Y_val)-1)/(len(Y_val)-X_val.shape[1]-1)]\n",
    "    }, index=['Train','Test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "secondary-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metrics for classification task\n",
    "def evaluate_classif(true, pred):\n",
    "    Precision = precision_score(true, pred, average = None)\n",
    "    Recall = recall_score(true, pred, average = None)\n",
    "    F1_score = f1_score(true, pred, average = None)\n",
    "    F_beta = fbeta_score(true, pred, average = None,beta=2)\n",
    "    \n",
    "    results = pd.DataFrame(np.array([Precision,Recall,F1_score,F_beta]))\n",
    "    results.index = ['Precision','Recall','F1_score','F_beta']\n",
    "    results.columns = list(np.unique(y_classif))\n",
    "    f1 = f1_score(true, pred, average='weighted')\n",
    "    return results, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-devon",
   "metadata": {},
   "source": [
    "#### I.II.I Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "tender-convenience",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split (no shuffle as we have timeseries data)\n",
    "data_regr_train, data_regr_test, target_regr_train, target_regr_test = train_test_split(data_regr.drop(target_regr, axis=1), \n",
    "                                                                                         data_regr[target_regr], \n",
    "                                                                                         shuffle=False, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "golden-increase",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying imputation/normalization\n",
    "x_regr_train = pd.DataFrame(num_pipe.fit_transform(data_regr_train))\n",
    "x_regr_test = pd.DataFrame(num_pipe.transform(data_regr_test))\n",
    "\n",
    "y_regr_train = pd.Series(target_regr_train)\n",
    "y_regr_test = pd.Series(target_regr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "native-result",
   "metadata": {},
   "source": [
    "#### NN - Tensorflow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "mysterious-scratch",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='sigmoid', input_shape=[len(x_regr_train.columns)]),\n",
    "    layers.Dense(64, activation='sigmoid'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "pregnant-hampton",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# training\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "\n",
    "history = model.fit(\n",
    "    x_regr_train, y_regr_train,\n",
    "    epochs=1000, validation_split = 0.2, verbose=0, callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "universal-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "pred_regr_train = model.predict(x_regr_train)\n",
    "pred_regr_test = model.predict(x_regr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "jewish-printing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Adj R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.086995</td>\n",
       "      <td>0.021494</td>\n",
       "      <td>0.146609</td>\n",
       "      <td>0.999622</td>\n",
       "      <td>0.999621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.113979</td>\n",
       "      <td>0.021885</td>\n",
       "      <td>0.147937</td>\n",
       "      <td>0.999485</td>\n",
       "      <td>0.999482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MAE       MSE      RMSE        R2    Adj R2\n",
       "Train  0.086995  0.021494  0.146609  0.999622  0.999621\n",
       "Test   0.113979  0.021885  0.147937  0.999485  0.999482"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "evaluate_regr(x_regr_train, x_regr_test, y_regr_train, y_regr_test, pred_regr_train, pred_regr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pointed-packet",
   "metadata": {},
   "source": [
    "#### Linear regression with box-cox transformation (previous approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "changing-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model & fitting\n",
    "linear_reg = LinearRegression()\n",
    "linear_reg.fit(x_regr_train, np.power(y_regr_train, 0.27));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "noble-champion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "linear_pred_regr_train = linear_reg.predict(x_regr_train)\n",
    "linear_pred_regr_test = linear_reg.predict(x_regr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "reverse-ratio",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Adj R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>0.028251</td>\n",
       "      <td>0.001606</td>\n",
       "      <td>0.040074</td>\n",
       "      <td>0.987980</td>\n",
       "      <td>0.987962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>0.060166</td>\n",
       "      <td>0.006081</td>\n",
       "      <td>0.077982</td>\n",
       "      <td>0.958851</td>\n",
       "      <td>0.958597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MAE       MSE      RMSE        R2    Adj R2\n",
       "Train  0.028251  0.001606  0.040074  0.987980  0.987962\n",
       "Test   0.060166  0.006081  0.077982  0.958851  0.958597"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "evaluate_regr(x_regr_train, x_regr_test, np.power(y_regr_train, 0.27), np.power(y_regr_test, 0.27), linear_pred_regr_train, linear_pred_regr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-offer",
   "metadata": {},
   "source": [
    "#### NN - Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "written-vietnamese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to demanded types\n",
    "x_regr_train_tensor = torch.tensor(x_regr_train.values.astype(np.float32))\n",
    "y_regr_train_tensor = torch.tensor(y_regr_train.values.astype(np.float32)) \n",
    "x, y = Variable(x_regr_train_tensor), Variable(y_regr_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "offshore-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "regr_net = torch.nn.Sequential(\n",
    "        torch.nn.Linear(11, 64),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(64, 64),\n",
    "        torch.nn.Sigmoid(),\n",
    "        torch.nn.Linear(64, 1),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "round-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining optimizer and loss function\n",
    "optimizer = torch.optim.RMSprop(regr_net.parameters(), lr=0.001)\n",
    "loss_func = torch.nn.MSELoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "expected-victim",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataset\n",
    "torch_dataset = Data.TensorDataset(x, y)\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,batch_size=64, \n",
    "    shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "skilled-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "min_val_loss = np.Inf\n",
    "iteration = 0\n",
    "early_stop = False # early stop flag\n",
    "\n",
    "for epoch in range(1000):\n",
    "    val_loss = 0\n",
    "    for step, (batch_x, batch_y) in enumerate(loader):\n",
    "        \n",
    "        b_x = Variable(batch_x)\n",
    "        b_y = Variable(batch_y)\n",
    "\n",
    "        prediction = regr_net(b_x)\n",
    "        loss = loss_func(prediction, b_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        val_loss += loss\n",
    "        val_loss = val_loss / len(loader)\n",
    "        if val_loss < min_val_loss:\n",
    "            epochs_no_improve = 0\n",
    "            min_val_loss = val_loss\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        iteration += 1\n",
    "        if epoch > 5 and epochs_no_improve == 50:\n",
    "            early_stop = True\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    if early_stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "cellular-puzzle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to demanded type\n",
    "x_regr_test_tensor = torch.tensor(x_regr_test.values.astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "third-eight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "pred_train = regr_net(Variable(x_regr_train_tensor)).data.cpu().numpy()\n",
    "pred_test = regr_net(Variable(x_regr_test_tensor)).data.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "orange-guyana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MAE</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>Adj R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Train</th>\n",
       "      <td>5.860660</td>\n",
       "      <td>56.799550</td>\n",
       "      <td>7.536548</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>-0.001294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test</th>\n",
       "      <td>6.072239</td>\n",
       "      <td>50.241453</td>\n",
       "      <td>7.088121</td>\n",
       "      <td>-0.182481</td>\n",
       "      <td>-0.189768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            MAE        MSE      RMSE        R2    Adj R2\n",
       "Train  5.860660  56.799550  7.536548  0.000239 -0.001294\n",
       "Test   6.072239  50.241453  7.088121 -0.182481 -0.189768"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "evaluate_regr(x_regr_train, x_regr_test, y_regr_train, y_regr_test, pred_train, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "activated-collins",
   "metadata": {},
   "source": [
    "#### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-couple",
   "metadata": {},
   "source": [
    "Previous approach - linear regression combined with box-cox transformation - gave better results than neural networks. The reason may be inadequate learning rate, number of layers or their dimensions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psychological-field",
   "metadata": {},
   "source": [
    "#### I.II.II Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "convenient-kruger",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding of target variable\n",
    "y_classif = data_classif[target_classif]\n",
    "y_classif_encoded = LabelEncoder().fit_transform(y_classif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "outstanding-merit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test split\n",
    "data_classif_train, data_classif_test, target_classif_train, target_classif_test = train_test_split(\n",
    "                                                                                    data_classif.drop(target_classif, axis=1), \n",
    "                                                                                    y_classif_encoded, \n",
    "                                                                                    stratify=y_classif_encoded, \n",
    "                                                                                    random_state=123, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "senior-emission",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying encoding, imputation & normalization\n",
    "x_classif_train = pd.DataFrame(scaler.fit_transform(pipe.fit_transform(data_classif_train)))\n",
    "x_classif_test = pd.DataFrame(scaler.transform(pipe.transform(data_classif_test)))\n",
    "\n",
    "y_classif_train = pd.Series(target_classif_train)\n",
    "y_classif_test = pd.Series(target_classif_test)\n",
    "\n",
    "x_classif_train.columns = classif_column_names\n",
    "x_classif_test.columns = classif_column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-neighbor",
   "metadata": {},
   "source": [
    "#### NN - Tensorflow/Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "suspended-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot-encoding of target variable\n",
    "y_classif_train_enc = to_categorical(y_classif_train)\n",
    "y_classif_test_enc = to_categorical(y_classif_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "resistant-hampton",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(64, activation='sigmoid', input_shape=[len(x_classif_train.columns)]),\n",
    "    layers.Dense(64, activation='sigmoid'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics= tfa.metrics.F1Score(num_classes = 3, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "august-center",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=50)\n",
    "\n",
    "history = model.fit(\n",
    "    x_classif_train, y_classif_train_enc,\n",
    "    epochs=1000, validation_split = 0.2, verbose=0, callbacks=early_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dental-death",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "pred_classif_train = model.predict(x_classif_train)\n",
    "pred_classif_test = model.predict(x_classif_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "arctic-wellington",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 score:  0.9784943808871924\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compensated_hypothyroid</th>\n",
       "      <th>negative</th>\n",
       "      <th>primary_hypothyroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.987143</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.992816</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_score</th>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.989971</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F_beta</th>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.991676</td>\n",
       "      <td>0.824176</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           compensated_hypothyroid  negative  primary_hypothyroid\n",
       "Precision                 0.820513  0.987143             1.000000\n",
       "Recall                    0.820513  0.992816             0.789474\n",
       "F1_score                  0.820513  0.989971             0.882353\n",
       "F_beta                    0.820513  0.991676             0.824176"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "results, f1 = evaluate_classif(np.argmax(y_classif_test_enc, axis=1), np.argmax(pred_classif_test, axis=1))\n",
    "print('Micro F1 score: ', f1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eligible-booking",
   "metadata": {},
   "source": [
    "#### SVM with hyperparameters tuning (previous approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "olive-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model & prediction\n",
    "svm = SVC(kernel='linear', C=1000) # tuned hyperparameters\n",
    "svm.fit(x_classif_train, y_classif_train)\n",
    "pred_test = svm.predict(x_classif_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "impossible-rapid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 score:  0.9788248702803625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compensated_hypothyroid</th>\n",
       "      <th>negative</th>\n",
       "      <th>primary_hypothyroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.991367</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.989943</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_score</th>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.990654</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F_beta</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.990227</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           compensated_hypothyroid  negative  primary_hypothyroid\n",
       "Precision                 0.795455  0.991367             0.933333\n",
       "Recall                    0.897436  0.989943             0.736842\n",
       "F1_score                  0.843373  0.990654             0.823529\n",
       "F_beta                    0.875000  0.990227             0.769231"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "results, f1 = evaluate_classif(y_classif_test, pred_test)\n",
    "print('Micro F1 score: ', f1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-version",
   "metadata": {},
   "source": [
    "#### NN - Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "potential-campbell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to demanded types\n",
    "x_classif_train_tensor = torch.tensor(x_classif_train.values.astype(np.float32))\n",
    "y_classif_train_tensor = torch.tensor(y_classif_train.values.astype(np.float32)) \n",
    "y_classif_train_tensor = y_classif_train_tensor.type(torch.LongTensor)\n",
    "x, y = Variable(x_classif_train_tensor), Variable(y_classif_train_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "quality-portal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "torch_dataset = Data.TensorDataset(x, y)\n",
    "loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "guided-strip",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, D_in, H, D_out):\n",
    "        super(Net,self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H)\n",
    "        self.linear2 = nn.Linear(H, D_out)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = torch.sigmoid(self.linear1(x))  \n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "acting-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# layers dimension\n",
    "input_dim = 28 \n",
    "hidden_dim = 64 \n",
    "output_dim = 3 \n",
    "# model\n",
    "model = Net(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "documentary-february",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer & loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "sufficient-disease",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "n_epochs = 1000\n",
    "loss_list = []\n",
    "min_val_loss = np.Inf\n",
    "iteration = 0\n",
    "early_stop = False # early stop flag\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    val_loss=0\n",
    "    for x, y in loader:\n",
    "        optimizer.zero_grad()\n",
    "        z=model(x)\n",
    "        loss=criterion(z,y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_list.append(loss.data)\n",
    "                \n",
    "        val_loss += loss\n",
    "        val_loss = val_loss / len(loader)\n",
    "        if val_loss < min_val_loss:\n",
    "            epochs_no_improve = 0\n",
    "            min_val_loss = val_loss\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "        iteration += 1\n",
    "        if epoch > 5 and epochs_no_improve == 50:\n",
    "            early_stop = True\n",
    "            break\n",
    "        else:\n",
    "            continue\n",
    "        break\n",
    "\n",
    "    if early_stop:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "automotive-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "pred = torch.max(model(x_test).data,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "painted-special",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 score:  0.9798404413532333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compensated_hypothyroid</th>\n",
       "      <th>negative</th>\n",
       "      <th>primary_hypothyroid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.988555</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.992816</td>\n",
       "      <td>0.789474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1_score</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.990681</td>\n",
       "      <td>0.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F_beta</th>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.991961</td>\n",
       "      <td>0.815217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           compensated_hypothyroid  negative  primary_hypothyroid\n",
       "Precision                 0.846154  0.988555             0.937500\n",
       "Recall                    0.846154  0.992816             0.789474\n",
       "F1_score                  0.846154  0.990681             0.857143\n",
       "F_beta                    0.846154  0.991961             0.815217"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "results, f1 = evaluate_classif(y_classif_test, pred.indices)\n",
    "print('Micro F1 score: ', f1)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "british-benefit",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "\n",
    "All methods (both neural networks and previous approach (SVM with tuned hyperparameters)) gave similar, good results, as even the minority classes were properly identified (mostly)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fantastic-detroit",
   "metadata": {},
   "source": [
    "## II. CV part"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-process",
   "metadata": {},
   "source": [
    "### II.I Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "gorgeous-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "clean-meter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 498 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# basic augmentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'hotdog__not_hotdog/train',  \n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  \n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'hotdog__not_hotdog/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "atmospheric-aquatic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 14s 368ms/step - loss: 0.7771 - accuracy: 0.4896 - val_loss: 0.6945 - val_accuracy: 0.4980\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 11s 356ms/step - loss: 0.7023 - accuracy: 0.5498 - val_loss: 0.6958 - val_accuracy: 0.5403\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 11s 367ms/step - loss: 0.6906 - accuracy: 0.5519 - val_loss: 0.6953 - val_accuracy: 0.4960\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 11s 368ms/step - loss: 0.6897 - accuracy: 0.5809 - val_loss: 0.6985 - val_accuracy: 0.5565\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 12s 385ms/step - loss: 0.6789 - accuracy: 0.5892 - val_loss: 0.7618 - val_accuracy: 0.5484\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 12s 371ms/step - loss: 0.6655 - accuracy: 0.5975 - val_loss: 0.7987 - val_accuracy: 0.5625\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 11s 368ms/step - loss: 0.6713 - accuracy: 0.6183 - val_loss: 0.6919 - val_accuracy: 0.5726\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 12s 373ms/step - loss: 0.6505 - accuracy: 0.6390 - val_loss: 0.7317 - val_accuracy: 0.5726\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 12s 372ms/step - loss: 0.6395 - accuracy: 0.6660 - val_loss: 0.7030 - val_accuracy: 0.5706\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 12s 387ms/step - loss: 0.6188 - accuracy: 0.6556 - val_loss: 0.7637 - val_accuracy: 0.5968\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 12s 380ms/step - loss: 0.6101 - accuracy: 0.7033 - val_loss: 0.7028 - val_accuracy: 0.5706\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 11s 367ms/step - loss: 0.6203 - accuracy: 0.6722 - val_loss: 0.6956 - val_accuracy: 0.6169\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 13s 414ms/step - loss: 0.5737 - accuracy: 0.6992 - val_loss: 0.8597 - val_accuracy: 0.5625\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 12s 372ms/step - loss: 0.5638 - accuracy: 0.7137 - val_loss: 0.9192 - val_accuracy: 0.5746\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 12s 373ms/step - loss: 0.5360 - accuracy: 0.7199 - val_loss: 0.8522 - val_accuracy: 0.5948\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 12s 374ms/step - loss: 0.5661 - accuracy: 0.7199 - val_loss: 0.7781 - val_accuracy: 0.5806\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 13s 423ms/step - loss: 0.5362 - accuracy: 0.7635 - val_loss: 0.8035 - val_accuracy: 0.5907\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 12s 393ms/step - loss: 0.5176 - accuracy: 0.7573 - val_loss: 0.9208 - val_accuracy: 0.6190\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 12s 395ms/step - loss: 0.4512 - accuracy: 0.7722 - val_loss: 1.0162 - val_accuracy: 0.6008\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 15s 482ms/step - loss: 0.4708 - accuracy: 0.7697 - val_loss: 0.9254 - val_accuracy: 0.5907\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 15s 471ms/step - loss: 0.4683 - accuracy: 0.8029 - val_loss: 1.4419 - val_accuracy: 0.5544\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 15s 474ms/step - loss: 0.4507 - accuracy: 0.7801 - val_loss: 1.1176 - val_accuracy: 0.6210\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 14s 440ms/step - loss: 0.4464 - accuracy: 0.7946 - val_loss: 1.0556 - val_accuracy: 0.5988\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 13s 417ms/step - loss: 0.4622 - accuracy: 0.7967 - val_loss: 0.9789 - val_accuracy: 0.5786\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 12s 375ms/step - loss: 0.4141 - accuracy: 0.8029 - val_loss: 1.2033 - val_accuracy: 0.6351\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 12s 394ms/step - loss: 0.4129 - accuracy: 0.8112 - val_loss: 1.3274 - val_accuracy: 0.6129\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 12s 396ms/step - loss: 0.4172 - accuracy: 0.8195 - val_loss: 1.0559 - val_accuracy: 0.6069\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 12s 382ms/step - loss: 0.4086 - accuracy: 0.8029 - val_loss: 1.2916 - val_accuracy: 0.5786\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 12s 379ms/step - loss: 0.3813 - accuracy: 0.8320 - val_loss: 1.1673 - val_accuracy: 0.6109\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 12s 387ms/step - loss: 0.3719 - accuracy: 0.8465 - val_loss: 1.1847 - val_accuracy: 0.6190\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 12s 400ms/step - loss: 0.3677 - accuracy: 0.8444 - val_loss: 1.4684 - val_accuracy: 0.5988\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 13s 407ms/step - loss: 0.3402 - accuracy: 0.8548 - val_loss: 1.4957 - val_accuracy: 0.5907\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 13s 425ms/step - loss: 0.3594 - accuracy: 0.8465 - val_loss: 1.2186 - val_accuracy: 0.5726\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 12s 373ms/step - loss: 0.3044 - accuracy: 0.8817 - val_loss: 1.3533 - val_accuracy: 0.5887\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 12s 373ms/step - loss: 0.3079 - accuracy: 0.8610 - val_loss: 1.4282 - val_accuracy: 0.6048\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 11s 369ms/step - loss: 0.3219 - accuracy: 0.8548 - val_loss: 1.5571 - val_accuracy: 0.5988\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 11s 369ms/step - loss: 0.3075 - accuracy: 0.8797 - val_loss: 1.4865 - val_accuracy: 0.6008\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 12s 384ms/step - loss: 0.3272 - accuracy: 0.8776 - val_loss: 1.4022 - val_accuracy: 0.5746\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 11s 368ms/step - loss: 0.2756 - accuracy: 0.8880 - val_loss: 1.3789 - val_accuracy: 0.6210\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 11s 369ms/step - loss: 0.2686 - accuracy: 0.8838 - val_loss: 1.7723 - val_accuracy: 0.6028\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 11s 366ms/step - loss: 0.2814 - accuracy: 0.8797 - val_loss: 1.6465 - val_accuracy: 0.6008\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 11s 366ms/step - loss: 0.2740 - accuracy: 0.8880 - val_loss: 1.9878 - val_accuracy: 0.5887\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 12s 374ms/step - loss: 0.2873 - accuracy: 0.8900 - val_loss: 1.7539 - val_accuracy: 0.6028\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 13s 408ms/step - loss: 0.2504 - accuracy: 0.9025 - val_loss: 1.7974 - val_accuracy: 0.5968\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 14s 444ms/step - loss: 0.2473 - accuracy: 0.8921 - val_loss: 1.7660 - val_accuracy: 0.5907\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 14s 440ms/step - loss: 0.2431 - accuracy: 0.9025 - val_loss: 1.5190 - val_accuracy: 0.6230\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 14s 464ms/step - loss: 0.2408 - accuracy: 0.9066 - val_loss: 1.7304 - val_accuracy: 0.6129\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 13s 406ms/step - loss: 0.2270 - accuracy: 0.9066 - val_loss: 1.8359 - val_accuracy: 0.5968\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 15s 474ms/step - loss: 0.2299 - accuracy: 0.9025 - val_loss: 1.5635 - val_accuracy: 0.6028\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 13s 405ms/step - loss: 0.2040 - accuracy: 0.9129 - val_loss: 2.4183 - val_accuracy: 0.6230\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=498 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=500 // batch_size)\n",
    "model.save_weights('first_try.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "quick-probability",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 2.4123892784118652\n",
      "Accuracy : 0.6240000128746033\n"
     ]
    }
   ],
   "source": [
    "# validation results\n",
    "loss, acc = model.evaluate_generator(validation_generator)\n",
    "print('Loss :', loss)\n",
    "print('Accuracy :', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-volume",
   "metadata": {},
   "source": [
    "The result isn't really satisfactory - accuracy equal to 0.62 is quite low. This may be because of too small number of epochs or simply because of the small amount of training data in comparison to the validation set size."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-grant",
   "metadata": {},
   "source": [
    "#### Different augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "floral-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten()) \n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "radical-nashville",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 498 images belonging to 2 classes.\n",
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "\n",
    "# advanced augmentation \n",
    "train_datagen = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'hotdog__not_hotdog/train',  \n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')  \n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'hotdog__not_hotdog/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "grateful-alfred",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "31/31 [==============================] - 14s 400ms/step - loss: 0.7532 - accuracy: 0.4502 - val_loss: 0.6930 - val_accuracy: 0.5242\n",
      "Epoch 2/50\n",
      "31/31 [==============================] - 13s 406ms/step - loss: 0.6932 - accuracy: 0.5207 - val_loss: 0.6943 - val_accuracy: 0.5020\n",
      "Epoch 3/50\n",
      "31/31 [==============================] - 12s 394ms/step - loss: 0.6941 - accuracy: 0.5581 - val_loss: 0.7460 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "31/31 [==============================] - 14s 440ms/step - loss: 0.6929 - accuracy: 0.5504 - val_loss: 0.6850 - val_accuracy: 0.5645\n",
      "Epoch 5/50\n",
      "31/31 [==============================] - 13s 407ms/step - loss: 0.6839 - accuracy: 0.5602 - val_loss: 0.6799 - val_accuracy: 0.5323\n",
      "Epoch 6/50\n",
      "31/31 [==============================] - 13s 404ms/step - loss: 0.6844 - accuracy: 0.5747 - val_loss: 1.1090 - val_accuracy: 0.5000\n",
      "Epoch 7/50\n",
      "31/31 [==============================] - 13s 434ms/step - loss: 0.6910 - accuracy: 0.5851 - val_loss: 0.6739 - val_accuracy: 0.5706\n",
      "Epoch 8/50\n",
      "31/31 [==============================] - 15s 493ms/step - loss: 0.6888 - accuracy: 0.5581 - val_loss: 0.6790 - val_accuracy: 0.5585\n",
      "Epoch 9/50\n",
      "31/31 [==============================] - 14s 449ms/step - loss: 0.6723 - accuracy: 0.6266 - val_loss: 0.6791 - val_accuracy: 0.5625\n",
      "Epoch 10/50\n",
      "31/31 [==============================] - 14s 442ms/step - loss: 0.6631 - accuracy: 0.6037 - val_loss: 0.7175 - val_accuracy: 0.5242\n",
      "Epoch 11/50\n",
      "31/31 [==============================] - 12s 395ms/step - loss: 0.6693 - accuracy: 0.5934 - val_loss: 0.6788 - val_accuracy: 0.5524\n",
      "Epoch 12/50\n",
      "31/31 [==============================] - 12s 385ms/step - loss: 0.6886 - accuracy: 0.6203 - val_loss: 0.6876 - val_accuracy: 0.5524\n",
      "Epoch 13/50\n",
      "31/31 [==============================] - 14s 442ms/step - loss: 0.6649 - accuracy: 0.6266 - val_loss: 0.7188 - val_accuracy: 0.5685\n",
      "Epoch 14/50\n",
      "31/31 [==============================] - 12s 395ms/step - loss: 0.6696 - accuracy: 0.6120 - val_loss: 0.9750 - val_accuracy: 0.5060\n",
      "Epoch 15/50\n",
      "31/31 [==============================] - 12s 394ms/step - loss: 0.6665 - accuracy: 0.6224 - val_loss: 0.7458 - val_accuracy: 0.5484\n",
      "Epoch 16/50\n",
      "31/31 [==============================] - 12s 386ms/step - loss: 0.6760 - accuracy: 0.5954 - val_loss: 0.6809 - val_accuracy: 0.5423\n",
      "Epoch 17/50\n",
      "31/31 [==============================] - 12s 385ms/step - loss: 0.6575 - accuracy: 0.6494 - val_loss: 0.6992 - val_accuracy: 0.5585\n",
      "Epoch 18/50\n",
      "31/31 [==============================] - 12s 384ms/step - loss: 0.6595 - accuracy: 0.6286 - val_loss: 0.7104 - val_accuracy: 0.5444\n",
      "Epoch 19/50\n",
      "31/31 [==============================] - 12s 396ms/step - loss: 0.6590 - accuracy: 0.6100 - val_loss: 0.6996 - val_accuracy: 0.5423\n",
      "Epoch 20/50\n",
      "31/31 [==============================] - 12s 392ms/step - loss: 0.6488 - accuracy: 0.6452 - val_loss: 0.6843 - val_accuracy: 0.5444\n",
      "Epoch 21/50\n",
      "31/31 [==============================] - 12s 389ms/step - loss: 0.6625 - accuracy: 0.6369 - val_loss: 0.6766 - val_accuracy: 0.5726\n",
      "Epoch 22/50\n",
      "31/31 [==============================] - 12s 387ms/step - loss: 0.6515 - accuracy: 0.6452 - val_loss: 0.6754 - val_accuracy: 0.5806\n",
      "Epoch 23/50\n",
      "31/31 [==============================] - 12s 385ms/step - loss: 0.6542 - accuracy: 0.6494 - val_loss: 0.6778 - val_accuracy: 0.5726\n",
      "Epoch 24/50\n",
      "31/31 [==============================] - 12s 400ms/step - loss: 0.6554 - accuracy: 0.6411 - val_loss: 0.6948 - val_accuracy: 0.5806\n",
      "Epoch 25/50\n",
      "31/31 [==============================] - 13s 427ms/step - loss: 0.6404 - accuracy: 0.6286 - val_loss: 0.6805 - val_accuracy: 0.5746\n",
      "Epoch 26/50\n",
      "31/31 [==============================] - 12s 388ms/step - loss: 0.6579 - accuracy: 0.6452 - val_loss: 0.6757 - val_accuracy: 0.5827\n",
      "Epoch 27/50\n",
      "31/31 [==============================] - 13s 405ms/step - loss: 0.6399 - accuracy: 0.6494 - val_loss: 0.7333 - val_accuracy: 0.5121\n",
      "Epoch 28/50\n",
      "31/31 [==============================] - 12s 393ms/step - loss: 0.6281 - accuracy: 0.6512 - val_loss: 0.7028 - val_accuracy: 0.5484\n",
      "Epoch 29/50\n",
      "31/31 [==============================] - 12s 383ms/step - loss: 0.6462 - accuracy: 0.6515 - val_loss: 0.7236 - val_accuracy: 0.5544\n",
      "Epoch 30/50\n",
      "31/31 [==============================] - 12s 383ms/step - loss: 0.6474 - accuracy: 0.6639 - val_loss: 0.6993 - val_accuracy: 0.5746\n",
      "Epoch 31/50\n",
      "31/31 [==============================] - 12s 381ms/step - loss: 0.6455 - accuracy: 0.6349 - val_loss: 0.7367 - val_accuracy: 0.5746\n",
      "Epoch 32/50\n",
      "31/31 [==============================] - 12s 396ms/step - loss: 0.6218 - accuracy: 0.6867 - val_loss: 0.7001 - val_accuracy: 0.5685\n",
      "Epoch 33/50\n",
      "31/31 [==============================] - 12s 389ms/step - loss: 0.6332 - accuracy: 0.6577 - val_loss: 0.6642 - val_accuracy: 0.6008\n",
      "Epoch 34/50\n",
      "31/31 [==============================] - 12s 399ms/step - loss: 0.6267 - accuracy: 0.6598 - val_loss: 0.6686 - val_accuracy: 0.6008\n",
      "Epoch 35/50\n",
      "31/31 [==============================] - 12s 390ms/step - loss: 0.6274 - accuracy: 0.6743 - val_loss: 0.6765 - val_accuracy: 0.5867\n",
      "Epoch 36/50\n",
      "31/31 [==============================] - 12s 400ms/step - loss: 0.6074 - accuracy: 0.6763 - val_loss: 0.7910 - val_accuracy: 0.5605\n",
      "Epoch 37/50\n",
      "31/31 [==============================] - 12s 393ms/step - loss: 0.6185 - accuracy: 0.6826 - val_loss: 0.6667 - val_accuracy: 0.6210\n",
      "Epoch 38/50\n",
      "31/31 [==============================] - 12s 400ms/step - loss: 0.6190 - accuracy: 0.6805 - val_loss: 0.6531 - val_accuracy: 0.6048\n",
      "Epoch 39/50\n",
      "31/31 [==============================] - 12s 391ms/step - loss: 0.6157 - accuracy: 0.6909 - val_loss: 0.6737 - val_accuracy: 0.6089\n",
      "Epoch 40/50\n",
      "31/31 [==============================] - 12s 392ms/step - loss: 0.6316 - accuracy: 0.6618 - val_loss: 0.6918 - val_accuracy: 0.5907\n",
      "Epoch 41/50\n",
      "31/31 [==============================] - 12s 404ms/step - loss: 0.6120 - accuracy: 0.6826 - val_loss: 0.7256 - val_accuracy: 0.5948\n",
      "Epoch 42/50\n",
      "31/31 [==============================] - 13s 428ms/step - loss: 0.5853 - accuracy: 0.6888 - val_loss: 0.8132 - val_accuracy: 0.5867\n",
      "Epoch 43/50\n",
      "31/31 [==============================] - 13s 412ms/step - loss: 0.6087 - accuracy: 0.6805 - val_loss: 0.7039 - val_accuracy: 0.6109\n",
      "Epoch 44/50\n",
      "31/31 [==============================] - 12s 394ms/step - loss: 0.5990 - accuracy: 0.6971 - val_loss: 0.7605 - val_accuracy: 0.5726\n",
      "Epoch 45/50\n",
      "31/31 [==============================] - 12s 395ms/step - loss: 0.6291 - accuracy: 0.6763 - val_loss: 0.6861 - val_accuracy: 0.5867\n",
      "Epoch 46/50\n",
      "31/31 [==============================] - 12s 403ms/step - loss: 0.6161 - accuracy: 0.6826 - val_loss: 0.6605 - val_accuracy: 0.5867\n",
      "Epoch 47/50\n",
      "31/31 [==============================] - 12s 388ms/step - loss: 0.5957 - accuracy: 0.6929 - val_loss: 0.7955 - val_accuracy: 0.5423\n",
      "Epoch 48/50\n",
      "31/31 [==============================] - 13s 421ms/step - loss: 0.6090 - accuracy: 0.7178 - val_loss: 0.6540 - val_accuracy: 0.6109\n",
      "Epoch 49/50\n",
      "31/31 [==============================] - 13s 407ms/step - loss: 0.5915 - accuracy: 0.7033 - val_loss: 0.8673 - val_accuracy: 0.5605\n",
      "Epoch 50/50\n",
      "31/31 [==============================] - 12s 384ms/step - loss: 0.5834 - accuracy: 0.6992 - val_loss: 1.2529 - val_accuracy: 0.5444\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=498 // batch_size,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=500 // batch_size)\n",
    "model.save_weights('second_try.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "associate-characterization",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss : 1.2535589933395386\n",
      "Accuracy : 0.5440000295639038\n"
     ]
    }
   ],
   "source": [
    "# validation results\n",
    "loss, acc = model.evaluate_generator(validation_generator)\n",
    "print('Loss :', loss)\n",
    "print('Accuracy :', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-ivory",
   "metadata": {},
   "source": [
    "After changing augmentation we get even worse results than before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "useful-ridge",
   "metadata": {},
   "source": [
    "### II.II Pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "automated-phase",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = applications.VGG16(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "atomic-offering",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 498 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = datagen.flow_from_directory(\n",
    "        'hotdog__not_hotdog/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=16,\n",
    "        class_mode=None, \n",
    "        shuffle=False)  \n",
    "\n",
    "bottleneck_features_train = model.predict_generator(generator, 31)\n",
    "np.save(open('bottleneck_features_train', 'wb'), bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "female-intersection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = datagen.flow_from_directory(\n",
    "        'hotdog__not_hotdog/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=16,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "bottleneck_features_validation = model.predict_generator(generator, 31)\n",
    "np.save(open('bottleneck_features_validation', 'wb'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "extraordinary-satellite",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 32ms/step - loss: 4.9320 - accuracy: 0.6213 - val_loss: 0.6523 - val_accuracy: 0.7379\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5133 - accuracy: 0.7352 - val_loss: 0.5697 - val_accuracy: 0.7621\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3753 - accuracy: 0.7631 - val_loss: 0.5627 - val_accuracy: 0.7903\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3392 - accuracy: 0.7952 - val_loss: 0.7165 - val_accuracy: 0.7641\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3089 - accuracy: 0.8083 - val_loss: 0.6380 - val_accuracy: 0.7661\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2244 - accuracy: 0.8795 - val_loss: 0.6683 - val_accuracy: 0.7702\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2304 - accuracy: 0.8590 - val_loss: 0.8186 - val_accuracy: 0.7883\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2209 - accuracy: 0.8656 - val_loss: 0.7537 - val_accuracy: 0.7823\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2602 - accuracy: 0.8411 - val_loss: 0.8523 - val_accuracy: 0.7742\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1890 - accuracy: 0.8992 - val_loss: 0.9042 - val_accuracy: 0.7883\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2605 - accuracy: 0.8908 - val_loss: 0.7321 - val_accuracy: 0.7883\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2058 - accuracy: 0.8814 - val_loss: 0.7553 - val_accuracy: 0.7944\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1705 - accuracy: 0.9030 - val_loss: 0.8372 - val_accuracy: 0.7944\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1699 - accuracy: 0.8909 - val_loss: 0.9628 - val_accuracy: 0.7863\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1303 - accuracy: 0.9240 - val_loss: 0.8725 - val_accuracy: 0.7802\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1600 - accuracy: 0.9138 - val_loss: 0.9303 - val_accuracy: 0.7702\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1320 - accuracy: 0.9002 - val_loss: 0.9726 - val_accuracy: 0.7762\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1471 - accuracy: 0.9170 - val_loss: 1.0636 - val_accuracy: 0.7681\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1414 - accuracy: 0.9204 - val_loss: 0.8056 - val_accuracy: 0.7661\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1423 - accuracy: 0.9013 - val_loss: 1.0807 - val_accuracy: 0.7621\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1807 - accuracy: 0.9168 - val_loss: 0.9649 - val_accuracy: 0.7823\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1200 - accuracy: 0.9180 - val_loss: 1.1434 - val_accuracy: 0.7984\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1037 - accuracy: 0.9168 - val_loss: 1.1732 - val_accuracy: 0.7581\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1203 - accuracy: 0.9411 - val_loss: 1.0198 - val_accuracy: 0.7581\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1364 - accuracy: 0.9248 - val_loss: 1.1106 - val_accuracy: 0.7722\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1184 - accuracy: 0.9177 - val_loss: 0.9841 - val_accuracy: 0.7702\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1358 - accuracy: 0.9301 - val_loss: 1.0875 - val_accuracy: 0.7762\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1415 - accuracy: 0.9016 - val_loss: 0.9381 - val_accuracy: 0.7601\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1311 - accuracy: 0.9004 - val_loss: 0.9692 - val_accuracy: 0.7823\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1376 - accuracy: 0.9054 - val_loss: 1.0406 - val_accuracy: 0.7681\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1207 - accuracy: 0.9399 - val_loss: 1.1056 - val_accuracy: 0.7702\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1237 - accuracy: 0.9238 - val_loss: 1.2188 - val_accuracy: 0.7661\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1410 - accuracy: 0.9209 - val_loss: 1.0937 - val_accuracy: 0.7802\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2324 - accuracy: 0.9001 - val_loss: 1.0706 - val_accuracy: 0.7762\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1418 - accuracy: 0.9296 - val_loss: 1.1048 - val_accuracy: 0.7581\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1215 - accuracy: 0.9461 - val_loss: 1.1411 - val_accuracy: 0.7681\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1370 - accuracy: 0.9135 - val_loss: 1.0181 - val_accuracy: 0.7702\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1140 - accuracy: 0.9288 - val_loss: 1.0387 - val_accuracy: 0.7762\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1198 - accuracy: 0.9044 - val_loss: 1.0863 - val_accuracy: 0.7661\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1218 - accuracy: 0.9230 - val_loss: 1.3721 - val_accuracy: 0.7802\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2070 - accuracy: 0.9208 - val_loss: 1.1668 - val_accuracy: 0.7762\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1472 - accuracy: 0.9330 - val_loss: 0.9390 - val_accuracy: 0.7802\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1317 - accuracy: 0.9123 - val_loss: 1.0300 - val_accuracy: 0.7802\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1254 - accuracy: 0.9241 - val_loss: 1.3048 - val_accuracy: 0.7823\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1551 - accuracy: 0.9274 - val_loss: 1.7640 - val_accuracy: 0.7802\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.1176 - accuracy: 0.9314 - val_loss: 1.3532 - val_accuracy: 0.7923\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1119 - accuracy: 0.9468 - val_loss: 1.3465 - val_accuracy: 0.7722\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1377 - accuracy: 0.9046 - val_loss: 1.4855 - val_accuracy: 0.7782\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.9360 - val_loss: 1.3915 - val_accuracy: 0.7722\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1305 - accuracy: 0.9377 - val_loss: 1.4762 - val_accuracy: 0.7742\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0850 - accuracy: 0.9409 - val_loss: 1.6839 - val_accuracy: 0.7823\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0936 - accuracy: 0.9476 - val_loss: 1.8460 - val_accuracy: 0.7843\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1003 - accuracy: 0.9499 - val_loss: 1.9081 - val_accuracy: 0.7863\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1426 - accuracy: 0.9330 - val_loss: 1.4792 - val_accuracy: 0.7863\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1309 - accuracy: 0.9373 - val_loss: 1.8853 - val_accuracy: 0.7641\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1381 - accuracy: 0.9234 - val_loss: 1.4550 - val_accuracy: 0.7762\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1423 - accuracy: 0.9474 - val_loss: 1.4740 - val_accuracy: 0.7762\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1089 - accuracy: 0.9498 - val_loss: 1.6165 - val_accuracy: 0.7782\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0651 - accuracy: 0.9667 - val_loss: 1.5747 - val_accuracy: 0.7702\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.1016 - accuracy: 0.9544 - val_loss: 1.3059 - val_accuracy: 0.7722\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1255 - accuracy: 0.9239 - val_loss: 1.6089 - val_accuracy: 0.7681\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1085 - accuracy: 0.9575 - val_loss: 1.6689 - val_accuracy: 0.7823\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0696 - accuracy: 0.9643 - val_loss: 1.8943 - val_accuracy: 0.7843\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0764 - accuracy: 0.9673 - val_loss: 1.8737 - val_accuracy: 0.7863\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0795 - accuracy: 0.9493 - val_loss: 1.4718 - val_accuracy: 0.7742\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1052 - accuracy: 0.9385 - val_loss: 1.7694 - val_accuracy: 0.7661\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1117 - accuracy: 0.9470 - val_loss: 1.6605 - val_accuracy: 0.7843\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1072 - accuracy: 0.9261 - val_loss: 1.5936 - val_accuracy: 0.7722\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.1167 - accuracy: 0.9513 - val_loss: 1.7300 - val_accuracy: 0.7702\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0990 - accuracy: 0.9368 - val_loss: 1.9737 - val_accuracy: 0.7782\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1053 - accuracy: 0.9416 - val_loss: 1.9800 - val_accuracy: 0.7762\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0813 - accuracy: 0.9441 - val_loss: 1.9908 - val_accuracy: 0.7823\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0609 - accuracy: 0.9705 - val_loss: 2.0235 - val_accuracy: 0.7802\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0818 - accuracy: 0.9312 - val_loss: 2.0006 - val_accuracy: 0.7641\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0740 - accuracy: 0.9601 - val_loss: 1.6415 - val_accuracy: 0.7742\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0945 - accuracy: 0.9460 - val_loss: 1.5891 - val_accuracy: 0.7782\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0910 - accuracy: 0.9411 - val_loss: 1.7826 - val_accuracy: 0.7823\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0548 - accuracy: 0.9760 - val_loss: 2.1359 - val_accuracy: 0.7823\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2186 - accuracy: 0.9478 - val_loss: 1.9021 - val_accuracy: 0.7843\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0611 - accuracy: 0.9632 - val_loss: 2.0900 - val_accuracy: 0.7823\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1590 - accuracy: 0.9492 - val_loss: 2.6245 - val_accuracy: 0.7681\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1265 - accuracy: 0.9470 - val_loss: 1.8665 - val_accuracy: 0.7641\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0861 - accuracy: 0.9352 - val_loss: 1.6987 - val_accuracy: 0.7702\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1026 - accuracy: 0.9419 - val_loss: 1.8363 - val_accuracy: 0.7782\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0694 - accuracy: 0.9510 - val_loss: 1.7135 - val_accuracy: 0.7823\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 6ms/step - loss: 0.1233 - accuracy: 0.9472 - val_loss: 1.7486 - val_accuracy: 0.7823\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0436 - accuracy: 0.9691 - val_loss: 1.8442 - val_accuracy: 0.7742\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0664 - accuracy: 0.9589 - val_loss: 1.8083 - val_accuracy: 0.7823\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0749 - accuracy: 0.9696 - val_loss: 1.8181 - val_accuracy: 0.7883\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0673 - accuracy: 0.9537 - val_loss: 2.0851 - val_accuracy: 0.7923\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0840 - accuracy: 0.9653 - val_loss: 1.8679 - val_accuracy: 0.7762\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0522 - accuracy: 0.9605 - val_loss: 2.0211 - val_accuracy: 0.7742\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0938 - accuracy: 0.9616 - val_loss: 2.2014 - val_accuracy: 0.7782\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0529 - accuracy: 0.9678 - val_loss: 2.3598 - val_accuracy: 0.7722\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0821 - accuracy: 0.9470 - val_loss: 2.0826 - val_accuracy: 0.7762\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0710 - accuracy: 0.9552 - val_loss: 1.9138 - val_accuracy: 0.7903\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0803 - accuracy: 0.9449 - val_loss: 1.9731 - val_accuracy: 0.7923\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0721 - accuracy: 0.9492 - val_loss: 2.1182 - val_accuracy: 0.7823\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1904 - accuracy: 0.9451 - val_loss: 2.0440 - val_accuracy: 0.7964\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0721 - accuracy: 0.9574 - val_loss: 2.4484 - val_accuracy: 0.7702\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(open('bottleneck_features_train', 'rb'))\n",
    "\n",
    "train_labels = np.array([0] * 249 + [1] * 249)\n",
    "\n",
    "validation_data = np.load(open('bottleneck_features_validation', 'rb'))\n",
    "validation_labels = np.array([0] * 250 + [1] * 250)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          epochs=100,\n",
    "          batch_size=16,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "model.save_weights('bottleneck_fc_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "ruled-cuisine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 4ms/step - loss: 2.4484 - accuracy: 0.7702\n",
      "Loss : 2.448391914367676\n",
      "Accuracy : 0.7701612710952759\n"
     ]
    }
   ],
   "source": [
    "# validation results\n",
    "loss, acc = model.evaluate(validation_data, validation_labels)\n",
    "print('Loss :', loss)\n",
    "print('Accuracy :', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-defense",
   "metadata": {},
   "source": [
    "We can see that with pre-trained model we get far better results than before - accuracy already after 50 epochs is around 0.8 ."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-garlic",
   "metadata": {},
   "source": [
    "#### Different pre-trained model (VGG19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "indirect-boring",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = applications.VGG19(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "stopped-austria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 498 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = datagen.flow_from_directory(\n",
    "        'hotdog__not_hotdog/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=16,\n",
    "        class_mode=None, \n",
    "        shuffle=False)  \n",
    "\n",
    "bottleneck_features_train = model.predict_generator(generator, 31)\n",
    "np.save(open('bottleneck_features_train_2', 'wb'), bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "invalid-championship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 498 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = datagen.flow_from_directory(\n",
    "        'hotdog__not_hotdog/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=16,\n",
    "        class_mode=None, \n",
    "        shuffle=False)  \n",
    "\n",
    "bottleneck_features_train = model.predict_generator(generator, 31)\n",
    "np.save(open('bottleneck_features_train_2', 'wb'), bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "marked-joining",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "generator = datagen.flow_from_directory(\n",
    "        'hotdog__not_hotdog/test',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=16,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "bottleneck_features_validation = model.predict_generator(generator, 31)\n",
    "np.save(open('bottleneck_features_validation_2', 'wb'), bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "refined-caribbean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 3s 30ms/step - loss: 4.2449 - accuracy: 0.6267 - val_loss: 0.6603 - val_accuracy: 0.7399\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.4622 - accuracy: 0.7992 - val_loss: 0.7363 - val_accuracy: 0.7359\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4672 - accuracy: 0.8182 - val_loss: 0.7816 - val_accuracy: 0.7399\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4067 - accuracy: 0.8353 - val_loss: 0.7213 - val_accuracy: 0.7742\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2767 - accuracy: 0.8618 - val_loss: 0.7244 - val_accuracy: 0.7520\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2596 - accuracy: 0.9109 - val_loss: 0.6845 - val_accuracy: 0.7903\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2331 - accuracy: 0.8955 - val_loss: 0.8458 - val_accuracy: 0.7883\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2502 - accuracy: 0.9110 - val_loss: 0.7265 - val_accuracy: 0.7823\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2608 - accuracy: 0.8876 - val_loss: 0.6643 - val_accuracy: 0.7923\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2346 - accuracy: 0.8923 - val_loss: 1.1350 - val_accuracy: 0.7762\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2355 - accuracy: 0.9224 - val_loss: 1.1073 - val_accuracy: 0.7944\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2091 - accuracy: 0.9160 - val_loss: 0.8720 - val_accuracy: 0.8065\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1818 - accuracy: 0.9333 - val_loss: 1.0946 - val_accuracy: 0.7923\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1736 - accuracy: 0.9382 - val_loss: 0.7844 - val_accuracy: 0.7944\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1604 - accuracy: 0.9360 - val_loss: 0.9083 - val_accuracy: 0.7863\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2241 - accuracy: 0.9203 - val_loss: 0.9956 - val_accuracy: 0.7964\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1442 - accuracy: 0.9309 - val_loss: 0.9643 - val_accuracy: 0.7964\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1362 - accuracy: 0.9410 - val_loss: 1.0557 - val_accuracy: 0.7742\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1467 - accuracy: 0.9389 - val_loss: 0.9420 - val_accuracy: 0.7883\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1862 - accuracy: 0.9233 - val_loss: 1.0311 - val_accuracy: 0.7782\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1544 - accuracy: 0.9391 - val_loss: 0.8731 - val_accuracy: 0.7944\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1150 - accuracy: 0.9554 - val_loss: 1.3170 - val_accuracy: 0.7903\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1791 - accuracy: 0.9391 - val_loss: 1.2158 - val_accuracy: 0.8105\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1095 - accuracy: 0.9715 - val_loss: 1.2699 - val_accuracy: 0.7923\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1234 - accuracy: 0.9484 - val_loss: 1.4625 - val_accuracy: 0.7964\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1198 - accuracy: 0.9323 - val_loss: 1.2005 - val_accuracy: 0.8024\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1561 - accuracy: 0.9284 - val_loss: 1.1794 - val_accuracy: 0.7984\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1329 - accuracy: 0.9534 - val_loss: 1.4148 - val_accuracy: 0.8085\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1290 - accuracy: 0.9417 - val_loss: 1.5412 - val_accuracy: 0.7823\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1489 - accuracy: 0.9490 - val_loss: 1.2386 - val_accuracy: 0.7964\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.1324 - accuracy: 0.9446 - val_loss: 1.1675 - val_accuracy: 0.7903\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1277 - accuracy: 0.9453 - val_loss: 1.5859 - val_accuracy: 0.7681\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1059 - accuracy: 0.9640 - val_loss: 1.6730 - val_accuracy: 0.7903\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.1292 - accuracy: 0.9414 - val_loss: 1.6230 - val_accuracy: 0.7802\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2012 - accuracy: 0.9690 - val_loss: 1.6063 - val_accuracy: 0.7944\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1217 - accuracy: 0.9588 - val_loss: 1.6625 - val_accuracy: 0.7823\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1159 - accuracy: 0.9525 - val_loss: 0.9236 - val_accuracy: 0.7883\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1178 - accuracy: 0.9588 - val_loss: 1.0365 - val_accuracy: 0.7883\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1191 - accuracy: 0.9466 - val_loss: 1.0697 - val_accuracy: 0.7883\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0997 - accuracy: 0.9485 - val_loss: 1.2326 - val_accuracy: 0.7984\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.1109 - accuracy: 0.9519 - val_loss: 1.4113 - val_accuracy: 0.7843\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0923 - accuracy: 0.9455 - val_loss: 1.6353 - val_accuracy: 0.8044\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1115 - accuracy: 0.9485 - val_loss: 1.5315 - val_accuracy: 0.7984\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0937 - accuracy: 0.9648 - val_loss: 1.3896 - val_accuracy: 0.7762\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1149 - accuracy: 0.9399 - val_loss: 1.1270 - val_accuracy: 0.7923\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1054 - accuracy: 0.9557 - val_loss: 1.2071 - val_accuracy: 0.7883\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0920 - accuracy: 0.9592 - val_loss: 1.3952 - val_accuracy: 0.7984\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1041 - accuracy: 0.9519 - val_loss: 1.3698 - val_accuracy: 0.7903\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.1146 - accuracy: 0.9438 - val_loss: 1.3548 - val_accuracy: 0.7984\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0958 - accuracy: 0.9574 - val_loss: 1.6777 - val_accuracy: 0.7903\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0847 - accuracy: 0.9640 - val_loss: 1.8734 - val_accuracy: 0.7823\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1125 - accuracy: 0.9563 - val_loss: 1.8795 - val_accuracy: 0.7944\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.1188 - accuracy: 0.9390 - val_loss: 1.4080 - val_accuracy: 0.7944\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0975 - accuracy: 0.9455 - val_loss: 1.4941 - val_accuracy: 0.7661\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0998 - accuracy: 0.9488 - val_loss: 1.6535 - val_accuracy: 0.8004\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0999 - accuracy: 0.9458 - val_loss: 1.5990 - val_accuracy: 0.8024\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.0985 - accuracy: 0.9652 - val_loss: 1.6753 - val_accuracy: 0.7782\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0918 - accuracy: 0.9729 - val_loss: 1.4052 - val_accuracy: 0.8065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1094 - accuracy: 0.9492 - val_loss: 1.4841 - val_accuracy: 0.8065\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0981 - accuracy: 0.9358 - val_loss: 1.6573 - val_accuracy: 0.7903\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1152 - accuracy: 0.9436 - val_loss: 1.4077 - val_accuracy: 0.8044\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1821 - accuracy: 0.9302 - val_loss: 1.3138 - val_accuracy: 0.8024\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0847 - accuracy: 0.9559 - val_loss: 1.5620 - val_accuracy: 0.7984\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1181 - accuracy: 0.9594 - val_loss: 1.8047 - val_accuracy: 0.7984\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1053 - accuracy: 0.9461 - val_loss: 1.5881 - val_accuracy: 0.7742\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0972 - accuracy: 0.9605 - val_loss: 1.2272 - val_accuracy: 0.7923\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.0848 - accuracy: 0.9582 - val_loss: 1.5285 - val_accuracy: 0.7883\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0961 - accuracy: 0.9578 - val_loss: 1.5602 - val_accuracy: 0.8024\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1014 - accuracy: 0.9570 - val_loss: 2.0838 - val_accuracy: 0.7984\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.1032 - accuracy: 0.9494 - val_loss: 1.8158 - val_accuracy: 0.7984\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0772 - accuracy: 0.9572 - val_loss: 1.9223 - val_accuracy: 0.7923\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1040 - accuracy: 0.9613 - val_loss: 1.9243 - val_accuracy: 0.8024\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.1259 - accuracy: 0.9315 - val_loss: 1.6475 - val_accuracy: 0.8105\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3109 - accuracy: 0.9176 - val_loss: 1.4292 - val_accuracy: 0.8065\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.1045 - accuracy: 0.9552 - val_loss: 1.4778 - val_accuracy: 0.7923\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0760 - accuracy: 0.9627 - val_loss: 1.5072 - val_accuracy: 0.8024\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0830 - accuracy: 0.9637 - val_loss: 1.4103 - val_accuracy: 0.8105\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0694 - accuracy: 0.9687 - val_loss: 1.5119 - val_accuracy: 0.8004\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0751 - accuracy: 0.9705 - val_loss: 1.5732 - val_accuracy: 0.8004\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0771 - accuracy: 0.9761 - val_loss: 1.7833 - val_accuracy: 0.7964\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1359 - accuracy: 0.9549 - val_loss: 1.5029 - val_accuracy: 0.8266\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1003 - accuracy: 0.9681 - val_loss: 1.3825 - val_accuracy: 0.8004\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0833 - accuracy: 0.9579 - val_loss: 1.4592 - val_accuracy: 0.8085\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0898 - accuracy: 0.9546 - val_loss: 1.5073 - val_accuracy: 0.8165\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0700 - accuracy: 0.9561 - val_loss: 1.7009 - val_accuracy: 0.8145\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0737 - accuracy: 0.9634 - val_loss: 1.8856 - val_accuracy: 0.8125\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0830 - accuracy: 0.9638 - val_loss: 1.8112 - val_accuracy: 0.8206\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0650 - accuracy: 0.9698 - val_loss: 1.9320 - val_accuracy: 0.8065\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0890 - accuracy: 0.9539 - val_loss: 1.5119 - val_accuracy: 0.8145\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0782 - accuracy: 0.9756 - val_loss: 1.4234 - val_accuracy: 0.8105\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1250 - accuracy: 0.9520 - val_loss: 1.3681 - val_accuracy: 0.8024\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0923 - accuracy: 0.9627 - val_loss: 1.4345 - val_accuracy: 0.8065\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0757 - accuracy: 0.9616 - val_loss: 1.3944 - val_accuracy: 0.8044\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0759 - accuracy: 0.9570 - val_loss: 1.3895 - val_accuracy: 0.8044\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0708 - accuracy: 0.9759 - val_loss: 1.5151 - val_accuracy: 0.8044\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0726 - accuracy: 0.9691 - val_loss: 1.6063 - val_accuracy: 0.8145\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.0508 - accuracy: 0.9710 - val_loss: 1.8931 - val_accuracy: 0.8145\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0551 - accuracy: 0.9750 - val_loss: 1.7785 - val_accuracy: 0.8145\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0552 - accuracy: 0.9742 - val_loss: 1.8600 - val_accuracy: 0.8085\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.0901 - accuracy: 0.9566 - val_loss: 1.8397 - val_accuracy: 0.8004\n"
     ]
    }
   ],
   "source": [
    "train_data = np.load(open('bottleneck_features_train_2', 'rb'))\n",
    "\n",
    "train_labels = np.array([0] * 248 + [1] * 248)\n",
    "\n",
    "validation_data = np.load(open('bottleneck_features_validation_2', 'rb'))\n",
    "validation_labels = np.array([0] * 248 + [1] * 248)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_data, train_labels,\n",
    "          epochs=100,\n",
    "          batch_size=16,\n",
    "          validation_data=(validation_data, validation_labels))\n",
    "model.save_weights('bottleneck_fc_model_2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "conservative-scholarship",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 3ms/step - loss: 1.8397 - accuracy: 0.8004\n",
      "Loss : 1.8396602869033813\n",
      "Accuracy : 0.8004032373428345\n"
     ]
    }
   ],
   "source": [
    "# validation results\n",
    "loss, acc = model.evaluate(validation_data, validation_labels)\n",
    "print('Loss :', loss)\n",
    "print('Accuracy :', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-webcam",
   "metadata": {},
   "source": [
    "We get slightly better results than the model used previously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gorgeous-length",
   "metadata": {},
   "source": [
    "#### Optimal learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "manufactured-vertical",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.1, 0.05, 0.01, 0.005, 0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "bottom-edition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "31/31 [==============================] - 10s 22ms/step - loss: 108.5490 - accuracy: 0.5262 - val_loss: 6.0405 - val_accuracy: 0.5464\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 46.7412 - accuracy: 0.5141 - val_loss: 0.7533 - val_accuracy: 0.5060\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 15.2972 - accuracy: 0.5000 - val_loss: 4.1606 - val_accuracy: 0.5464\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6291 - accuracy: 0.5464 - val_loss: 9.1540 - val_accuracy: 0.5786\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 8.0496 - accuracy: 0.5101 - val_loss: 0.6905 - val_accuracy: 0.5000\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 1.0154 - accuracy: 0.5302 - val_loss: 0.6968 - val_accuracy: 0.5040\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6685 - accuracy: 0.5524 - val_loss: 0.6975 - val_accuracy: 0.5000\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6729 - accuracy: 0.5161 - val_loss: 0.6920 - val_accuracy: 0.5040\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6774 - accuracy: 0.4798 - val_loss: 0.6928 - val_accuracy: 0.5040\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6649 - accuracy: 0.5141 - val_loss: 0.6915 - val_accuracy: 0.5040\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6691 - accuracy: 0.5060 - val_loss: 0.6949 - val_accuracy: 0.5000\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6719 - accuracy: 0.5081 - val_loss: 0.6904 - val_accuracy: 0.5040\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6725 - accuracy: 0.5161 - val_loss: 0.6915 - val_accuracy: 0.5000\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6732 - accuracy: 0.4960 - val_loss: 0.6907 - val_accuracy: 0.5000\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6760 - accuracy: 0.4859 - val_loss: 0.6904 - val_accuracy: 0.5040\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6703 - accuracy: 0.5181 - val_loss: 0.6909 - val_accuracy: 0.5000\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6623 - accuracy: 0.5202 - val_loss: 0.6915 - val_accuracy: 0.5040\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.6615 - accuracy: 0.5323 - val_loss: 0.6904 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6682 - accuracy: 0.5060 - val_loss: 0.6904 - val_accuracy: 0.5040\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6725 - accuracy: 0.5262 - val_loss: 0.6918 - val_accuracy: 0.5000\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6679 - accuracy: 0.5081 - val_loss: 0.6907 - val_accuracy: 0.5040\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6667 - accuracy: 0.5060 - val_loss: 0.6905 - val_accuracy: 0.5040\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6780 - accuracy: 0.4859 - val_loss: 0.6905 - val_accuracy: 0.5000\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6625 - accuracy: 0.5423 - val_loss: 0.6906 - val_accuracy: 0.5000\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6700 - accuracy: 0.4940 - val_loss: 0.6903 - val_accuracy: 0.5040\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6675 - accuracy: 0.4960 - val_loss: 0.6921 - val_accuracy: 0.5000\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6705 - accuracy: 0.4899 - val_loss: 0.6926 - val_accuracy: 0.5000\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6747 - accuracy: 0.5181 - val_loss: 0.6909 - val_accuracy: 0.5040\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6694 - accuracy: 0.5161 - val_loss: 0.6909 - val_accuracy: 0.5040\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6654 - accuracy: 0.4778 - val_loss: 0.6904 - val_accuracy: 0.5000\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6726 - accuracy: 0.4415 - val_loss: 0.6919 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6742 - accuracy: 0.5101 - val_loss: 0.6908 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6627 - accuracy: 0.5262 - val_loss: 0.6914 - val_accuracy: 0.5040\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6728 - accuracy: 0.5302 - val_loss: 0.6917 - val_accuracy: 0.5000\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6685 - accuracy: 0.5181 - val_loss: 0.6910 - val_accuracy: 0.5040\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6669 - accuracy: 0.5040 - val_loss: 0.6942 - val_accuracy: 0.5040\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6730 - accuracy: 0.5060 - val_loss: 0.6905 - val_accuracy: 0.5040\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6795 - accuracy: 0.4637 - val_loss: 0.6919 - val_accuracy: 0.5040\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.6691 - accuracy: 0.4919 - val_loss: 0.6906 - val_accuracy: 0.5040\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6697 - accuracy: 0.5423 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6722 - accuracy: 0.4919 - val_loss: 0.6904 - val_accuracy: 0.5040\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6705 - accuracy: 0.5282 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6791 - accuracy: 0.4919 - val_loss: 0.6916 - val_accuracy: 0.5040\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.6594 - accuracy: 0.5161 - val_loss: 0.6904 - val_accuracy: 0.5040\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6687 - accuracy: 0.5161 - val_loss: 0.6941 - val_accuracy: 0.5000\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6723 - accuracy: 0.5161 - val_loss: 0.6904 - val_accuracy: 0.5040\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.6728 - accuracy: 0.5141 - val_loss: 0.6924 - val_accuracy: 0.5000\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6779 - accuracy: 0.4879 - val_loss: 0.6905 - val_accuracy: 0.5040\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6676 - accuracy: 0.5020 - val_loss: 0.6904 - val_accuracy: 0.5000\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6737 - accuracy: 0.5121 - val_loss: 0.6904 - val_accuracy: 0.5040\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6717 - accuracy: 0.5423 - val_loss: 0.6931 - val_accuracy: 0.5000\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6715 - accuracy: 0.4859 - val_loss: 0.6911 - val_accuracy: 0.5000\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6759 - accuracy: 0.5000 - val_loss: 0.6908 - val_accuracy: 0.5040\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.6677 - accuracy: 0.5242 - val_loss: 0.6907 - val_accuracy: 0.5000\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6793 - accuracy: 0.5161 - val_loss: 0.6911 - val_accuracy: 0.5040\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6722 - accuracy: 0.4980 - val_loss: 0.6904 - val_accuracy: 0.5040\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.6714 - accuracy: 0.5242 - val_loss: 0.6968 - val_accuracy: 0.5000\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6708 - accuracy: 0.5202 - val_loss: 0.6907 - val_accuracy: 0.5040\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6740 - accuracy: 0.5020 - val_loss: 0.6918 - val_accuracy: 0.5040\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 0.6698 - accuracy: 0.5262 - val_loss: 0.6924 - val_accuracy: 0.5040\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6657 - accuracy: 0.5020 - val_loss: 0.6905 - val_accuracy: 0.5040\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6699 - accuracy: 0.4919 - val_loss: 0.6949 - val_accuracy: 0.5040\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6725 - accuracy: 0.5141 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6670 - accuracy: 0.5081 - val_loss: 0.6904 - val_accuracy: 0.5040\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6659 - accuracy: 0.5020 - val_loss: 0.6930 - val_accuracy: 0.5040\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6739 - accuracy: 0.4980 - val_loss: 0.6910 - val_accuracy: 0.5040\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.6697 - accuracy: 0.5000 - val_loss: 0.6910 - val_accuracy: 0.5000\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6692 - accuracy: 0.5242 - val_loss: 0.6927 - val_accuracy: 0.5040\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6622 - accuracy: 0.5081 - val_loss: 0.6905 - val_accuracy: 0.5040\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6759 - accuracy: 0.5141 - val_loss: 0.6908 - val_accuracy: 0.5000\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6679 - accuracy: 0.5383 - val_loss: 0.6955 - val_accuracy: 0.5040\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6744 - accuracy: 0.5202 - val_loss: 0.6904 - val_accuracy: 0.5000\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6669 - accuracy: 0.5282 - val_loss: 0.7006 - val_accuracy: 0.5040\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6769 - accuracy: 0.5202 - val_loss: 0.6903 - val_accuracy: 0.5040\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6807 - accuracy: 0.4940 - val_loss: 0.6906 - val_accuracy: 0.5000\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6692 - accuracy: 0.5141 - val_loss: 0.6928 - val_accuracy: 0.5040\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6670 - accuracy: 0.4960 - val_loss: 0.6912 - val_accuracy: 0.5000\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6679 - accuracy: 0.5343 - val_loss: 0.6926 - val_accuracy: 0.5040\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6567 - accuracy: 0.5544 - val_loss: 0.6940 - val_accuracy: 0.5000\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6752 - accuracy: 0.4960 - val_loss: 0.6909 - val_accuracy: 0.5040\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6714 - accuracy: 0.5101 - val_loss: 0.6906 - val_accuracy: 0.5000\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6649 - accuracy: 0.5101 - val_loss: 0.6911 - val_accuracy: 0.5000\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6697 - accuracy: 0.4879 - val_loss: 0.6906 - val_accuracy: 0.5000\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6712 - accuracy: 0.5161 - val_loss: 0.6904 - val_accuracy: 0.5040\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.6667 - accuracy: 0.5141 - val_loss: 0.6904 - val_accuracy: 0.5040\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6722 - accuracy: 0.4940 - val_loss: 0.6945 - val_accuracy: 0.5040\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6770 - accuracy: 0.5040 - val_loss: 0.6906 - val_accuracy: 0.5000\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6698 - accuracy: 0.5121 - val_loss: 0.6928 - val_accuracy: 0.5040\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6706 - accuracy: 0.5081 - val_loss: 0.6938 - val_accuracy: 0.5040\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6676 - accuracy: 0.5121 - val_loss: 0.6904 - val_accuracy: 0.5040\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6686 - accuracy: 0.5081 - val_loss: 0.6911 - val_accuracy: 0.5040\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6760 - accuracy: 0.5081 - val_loss: 0.6919 - val_accuracy: 0.5000\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6723 - accuracy: 0.5060 - val_loss: 0.6904 - val_accuracy: 0.5000\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6665 - accuracy: 0.5121 - val_loss: 0.6906 - val_accuracy: 0.5040\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6735 - accuracy: 0.4899 - val_loss: 0.6975 - val_accuracy: 0.5040\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.6698 - accuracy: 0.5101 - val_loss: 0.6918 - val_accuracy: 0.5000\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6696 - accuracy: 0.5121 - val_loss: 0.6905 - val_accuracy: 0.5000\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6719 - accuracy: 0.5202 - val_loss: 0.6983 - val_accuracy: 0.5040\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6719 - accuracy: 0.5101 - val_loss: 0.6911 - val_accuracy: 0.5000\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6709 - accuracy: 0.5000 - val_loss: 0.6913 - val_accuracy: 0.5000\n",
      "16/16 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5000\n",
      "Learning rate:  0.1  | Loss : 0.6912845373153687  | Accuracy : 0.5\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 80.8449 - accuracy: 0.5020 - val_loss: 0.7057 - val_accuracy: 0.5161\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 6.6094 - accuracy: 0.5907 - val_loss: 3.0764 - val_accuracy: 0.6694\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.2622 - accuracy: 0.5948 - val_loss: 0.7209 - val_accuracy: 0.5645\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 1.3785 - accuracy: 0.5504 - val_loss: 0.6791 - val_accuracy: 0.5605\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.9169 - accuracy: 0.5726 - val_loss: 0.6674 - val_accuracy: 0.5625\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6206 - accuracy: 0.5867 - val_loss: 0.6573 - val_accuracy: 0.5887\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6142 - accuracy: 0.5907 - val_loss: 0.6544 - val_accuracy: 0.5948\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 1.2448 - accuracy: 0.5806 - val_loss: 0.6472 - val_accuracy: 0.6190\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6235 - accuracy: 0.5847 - val_loss: 5.9158 - val_accuracy: 0.6452\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 2.8365 - accuracy: 0.5907 - val_loss: 0.6434 - val_accuracy: 0.6149\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6060 - accuracy: 0.5968 - val_loss: 0.6401 - val_accuracy: 0.6169\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6152 - accuracy: 0.5927 - val_loss: 0.6385 - val_accuracy: 0.6230\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6137 - accuracy: 0.5927 - val_loss: 0.6310 - val_accuracy: 0.6331\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 8ms/step - loss: 4.7858 - accuracy: 0.6048 - val_loss: 0.7087 - val_accuracy: 0.5907\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6062 - accuracy: 0.5988 - val_loss: 0.7150 - val_accuracy: 0.5645\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6225 - accuracy: 0.5766 - val_loss: 0.7151 - val_accuracy: 0.5645\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6371 - accuracy: 0.5423 - val_loss: 0.7126 - val_accuracy: 0.5706\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6282 - accuracy: 0.5726 - val_loss: 0.7092 - val_accuracy: 0.5806\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.6274 - accuracy: 0.58 - 0s 8ms/step - loss: 0.6199 - accuracy: 0.5766 - val_loss: 0.7035 - val_accuracy: 0.5968\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.7032 - accuracy: 0.6028 - val_loss: 0.6855 - val_accuracy: 0.5323\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6429 - accuracy: 0.5343 - val_loss: 0.6660 - val_accuracy: 0.5464\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6243 - accuracy: 0.5746 - val_loss: 0.6626 - val_accuracy: 0.5504\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6275 - accuracy: 0.5706 - val_loss: 0.6617 - val_accuracy: 0.5585\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6345 - accuracy: 0.5524 - val_loss: 0.6690 - val_accuracy: 0.5726\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6182 - accuracy: 0.5806 - val_loss: 0.6717 - val_accuracy: 0.5806\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6475 - accuracy: 0.5766 - val_loss: 0.6680 - val_accuracy: 0.5887\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6167 - accuracy: 0.5827 - val_loss: 0.6532 - val_accuracy: 0.5706\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6286 - accuracy: 0.5302 - val_loss: 0.6526 - val_accuracy: 0.5726\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6328 - accuracy: 0.5343 - val_loss: 0.6534 - val_accuracy: 0.5726\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.6198 - accuracy: 0.5766 - val_loss: 0.6523 - val_accuracy: 0.5726\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6298 - accuracy: 0.5685 - val_loss: 0.6522 - val_accuracy: 0.5726\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6251 - accuracy: 0.5706 - val_loss: 0.6520 - val_accuracy: 0.5766\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6240 - accuracy: 0.5423 - val_loss: 0.6509 - val_accuracy: 0.5766\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6277 - accuracy: 0.5746 - val_loss: 0.6505 - val_accuracy: 0.5766\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.6271 - accuracy: 0.5726 - val_loss: 0.6508 - val_accuracy: 0.5766\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6343 - accuracy: 0.5645 - val_loss: 0.6512 - val_accuracy: 0.5766\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6281 - accuracy: 0.5726 - val_loss: 0.6515 - val_accuracy: 0.5766\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6264 - accuracy: 0.5464 - val_loss: 0.6507 - val_accuracy: 0.5766\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6229 - accuracy: 0.5766 - val_loss: 0.6505 - val_accuracy: 0.5766\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6335 - accuracy: 0.5746 - val_loss: 0.6503 - val_accuracy: 0.5766\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6330 - accuracy: 0.5403 - val_loss: 0.6504 - val_accuracy: 0.5766\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6321 - accuracy: 0.5746 - val_loss: 0.6503 - val_accuracy: 0.5766\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6227 - accuracy: 0.5786 - val_loss: 0.6513 - val_accuracy: 0.5766\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6251 - accuracy: 0.5726 - val_loss: 0.6505 - val_accuracy: 0.5766\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6275 - accuracy: 0.5706 - val_loss: 0.6506 - val_accuracy: 0.5766\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6167 - accuracy: 0.5887 - val_loss: 0.6504 - val_accuracy: 0.5766\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6213 - accuracy: 0.5847 - val_loss: 0.6504 - val_accuracy: 0.5766\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6316 - accuracy: 0.5625 - val_loss: 0.6514 - val_accuracy: 0.5766\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6417 - accuracy: 0.4919 - val_loss: 0.6507 - val_accuracy: 0.5766\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6152 - accuracy: 0.5827 - val_loss: 0.6503 - val_accuracy: 0.5766\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6345 - accuracy: 0.5121 - val_loss: 0.6502 - val_accuracy: 0.5766\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6121 - accuracy: 0.5887 - val_loss: 0.6505 - val_accuracy: 0.5766\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6167 - accuracy: 0.5786 - val_loss: 0.6508 - val_accuracy: 0.5766\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6274 - accuracy: 0.5282 - val_loss: 0.6517 - val_accuracy: 0.5766\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6330 - accuracy: 0.5645 - val_loss: 0.6501 - val_accuracy: 0.5766\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6225 - accuracy: 0.5726 - val_loss: 0.6521 - val_accuracy: 0.5766\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6325 - accuracy: 0.5685 - val_loss: 0.6502 - val_accuracy: 0.5766\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6270 - accuracy: 0.5746 - val_loss: 0.6506 - val_accuracy: 0.5766\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.6216 - accuracy: 0.5726 - val_loss: 0.6507 - val_accuracy: 0.5766\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6228 - accuracy: 0.5746 - val_loss: 0.6512 - val_accuracy: 0.5766\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6242 - accuracy: 0.5383 - val_loss: 0.6505 - val_accuracy: 0.5766\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6324 - accuracy: 0.5685 - val_loss: 0.6503 - val_accuracy: 0.5766\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6314 - accuracy: 0.5665 - val_loss: 0.6503 - val_accuracy: 0.5766\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6352 - accuracy: 0.5645 - val_loss: 0.6522 - val_accuracy: 0.5766\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.6136 - accuracy: 0.5544 - val_loss: 0.6505 - val_accuracy: 0.5766\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6325 - accuracy: 0.5685 - val_loss: 0.6519 - val_accuracy: 0.5766\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6247 - accuracy: 0.5343 - val_loss: 0.6500 - val_accuracy: 0.5766\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6208 - accuracy: 0.5806 - val_loss: 0.6502 - val_accuracy: 0.5766\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6341 - accuracy: 0.5625 - val_loss: 0.6529 - val_accuracy: 0.5766\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6317 - accuracy: 0.5323 - val_loss: 0.6511 - val_accuracy: 0.5766\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6257 - accuracy: 0.5746 - val_loss: 0.6502 - val_accuracy: 0.5766\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6390 - accuracy: 0.5141 - val_loss: 0.6510 - val_accuracy: 0.5766\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6190 - accuracy: 0.5806 - val_loss: 0.6499 - val_accuracy: 0.5766\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.6120 - accuracy: 0.5907 - val_loss: 0.6511 - val_accuracy: 0.5766\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6262 - accuracy: 0.5484 - val_loss: 0.6503 - val_accuracy: 0.5766\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.6197 - accuracy: 0.5827 - val_loss: 0.6499 - val_accuracy: 0.5766\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6353 - accuracy: 0.5323 - val_loss: 0.6505 - val_accuracy: 0.5766\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6279 - accuracy: 0.5726 - val_loss: 0.6501 - val_accuracy: 0.5766\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6218 - accuracy: 0.5766 - val_loss: 0.6505 - val_accuracy: 0.5766\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6309 - accuracy: 0.5302 - val_loss: 0.6499 - val_accuracy: 0.5766\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6302 - accuracy: 0.5625 - val_loss: 0.6512 - val_accuracy: 0.5766\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6131 - accuracy: 0.5867 - val_loss: 0.6500 - val_accuracy: 0.5766\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.6401 - accuracy: 0.5585 - val_loss: 0.6505 - val_accuracy: 0.5766\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.6267 - accuracy: 0.5726 - val_loss: 0.6522 - val_accuracy: 0.5766\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6223 - accuracy: 0.5746 - val_loss: 0.6501 - val_accuracy: 0.5766\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6221 - accuracy: 0.5806 - val_loss: 0.6500 - val_accuracy: 0.5766\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6281 - accuracy: 0.5685 - val_loss: 0.6506 - val_accuracy: 0.5766\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6238 - accuracy: 0.5746 - val_loss: 0.6499 - val_accuracy: 0.5766\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6270 - accuracy: 0.5685 - val_loss: 0.6513 - val_accuracy: 0.5766\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6171 - accuracy: 0.5464 - val_loss: 0.6501 - val_accuracy: 0.5766\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6230 - accuracy: 0.5685 - val_loss: 0.6508 - val_accuracy: 0.5766\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6224 - accuracy: 0.5746 - val_loss: 0.6508 - val_accuracy: 0.5766\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6335 - accuracy: 0.5403 - val_loss: 0.6537 - val_accuracy: 0.5101\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6187 - accuracy: 0.5645 - val_loss: 0.6500 - val_accuracy: 0.5766\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6328 - accuracy: 0.5685 - val_loss: 0.6498 - val_accuracy: 0.5766\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6187 - accuracy: 0.5847 - val_loss: 0.6498 - val_accuracy: 0.5766\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6370 - accuracy: 0.5645 - val_loss: 0.6517 - val_accuracy: 0.5766\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6249 - accuracy: 0.5685 - val_loss: 0.6507 - val_accuracy: 0.5766\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6181 - accuracy: 0.5827 - val_loss: 0.6500 - val_accuracy: 0.5766\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6251 - accuracy: 0.5726 - val_loss: 0.6521 - val_accuracy: 0.5766\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.5766\n",
      "Learning rate:  0.05  | Loss : 0.6520873308181763  | Accuracy : 0.5766128897666931\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 1s 18ms/step - loss: 8.4693 - accuracy: 0.5524 - val_loss: 0.6534 - val_accuracy: 0.6351\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.7314 - accuracy: 0.6250 - val_loss: 0.6087 - val_accuracy: 0.6895\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5944 - accuracy: 0.7278 - val_loss: 0.6693 - val_accuracy: 0.7460\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5868 - accuracy: 0.7117 - val_loss: 0.6118 - val_accuracy: 0.6734\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5428 - accuracy: 0.6895 - val_loss: 0.6283 - val_accuracy: 0.7218\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5157 - accuracy: 0.7419 - val_loss: 0.6075 - val_accuracy: 0.7440\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5311 - accuracy: 0.7177 - val_loss: 0.6125 - val_accuracy: 0.6835\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5117 - accuracy: 0.7278 - val_loss: 0.6318 - val_accuracy: 0.7621\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.5071 - accuracy: 0.7399 - val_loss: 0.6747 - val_accuracy: 0.7500\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4875 - accuracy: 0.7500 - val_loss: 0.6263 - val_accuracy: 0.7198\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4510 - accuracy: 0.7883 - val_loss: 1.2973 - val_accuracy: 0.7520\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5112 - accuracy: 0.7722 - val_loss: 0.5732 - val_accuracy: 0.7399\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4741 - accuracy: 0.7480 - val_loss: 0.6467 - val_accuracy: 0.7742\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5133 - accuracy: 0.7177 - val_loss: 0.5912 - val_accuracy: 0.7238\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5338 - accuracy: 0.6935 - val_loss: 0.6158 - val_accuracy: 0.7339\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5125 - accuracy: 0.7137 - val_loss: 0.6585 - val_accuracy: 0.7339\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5352 - accuracy: 0.6895 - val_loss: 0.6772 - val_accuracy: 0.7440\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5060 - accuracy: 0.7258 - val_loss: 0.6210 - val_accuracy: 0.7218\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.5005 - accuracy: 0.7278 - val_loss: 0.6941 - val_accuracy: 0.7863\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.5165 - accuracy: 0.7157 - val_loss: 0.6543 - val_accuracy: 0.7177\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4847 - accuracy: 0.7419 - val_loss: 0.6608 - val_accuracy: 0.6653\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5183 - accuracy: 0.7077 - val_loss: 0.6718 - val_accuracy: 0.7520\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5090 - accuracy: 0.7238 - val_loss: 0.6195 - val_accuracy: 0.7460\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.4809 - accuracy: 0.7440 - val_loss: 0.7954 - val_accuracy: 0.7581\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.5036 - accuracy: 0.7339 - val_loss: 0.5712 - val_accuracy: 0.7399\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.4988 - accuracy: 0.7258 - val_loss: 0.6177 - val_accuracy: 0.7500\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4998 - accuracy: 0.7258 - val_loss: 0.6466 - val_accuracy: 0.7601\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4981 - accuracy: 0.7258 - val_loss: 0.6744 - val_accuracy: 0.7581\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5061 - accuracy: 0.7177 - val_loss: 0.7183 - val_accuracy: 0.7641\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.5052 - accuracy: 0.7198 - val_loss: 0.6929 - val_accuracy: 0.7419\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4665 - accuracy: 0.7560 - val_loss: 0.6800 - val_accuracy: 0.7379\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4982 - accuracy: 0.7258 - val_loss: 0.6592 - val_accuracy: 0.7278\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5101 - accuracy: 0.7137 - val_loss: 0.6658 - val_accuracy: 0.7278\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4927 - accuracy: 0.7319 - val_loss: 0.7702 - val_accuracy: 0.7540\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5006 - accuracy: 0.7298 - val_loss: 0.5957 - val_accuracy: 0.7379\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5125 - accuracy: 0.7097 - val_loss: 0.6516 - val_accuracy: 0.7681\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.5082 - accuracy: 0.7460 - val_loss: 0.7237 - val_accuracy: 0.7198\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.4869 - accuracy: 0.7379 - val_loss: 2.9321 - val_accuracy: 0.7762\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.4996 - accuracy: 0.7258 - val_loss: 1.1111 - val_accuracy: 0.6734\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.5380 - accuracy: 0.6895 - val_loss: 1.1981 - val_accuracy: 0.6915\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5226 - accuracy: 0.6996 - val_loss: 1.3280 - val_accuracy: 0.7137\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6213 - accuracy: 0.6552 - val_loss: 0.6822 - val_accuracy: 0.5585\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5811 - accuracy: 0.6431 - val_loss: 1.0111 - val_accuracy: 0.6895\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5576 - accuracy: 0.7077 - val_loss: 0.8083 - val_accuracy: 0.6976\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5233 - accuracy: 0.6996 - val_loss: 0.7268 - val_accuracy: 0.7016\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.4933 - accuracy: 0.7359 - val_loss: 1.0786 - val_accuracy: 0.7440\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4839 - accuracy: 0.7601 - val_loss: 0.9935 - val_accuracy: 0.7198\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.5225 - accuracy: 0.6996 - val_loss: 1.1244 - val_accuracy: 0.7157\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5035 - accuracy: 0.7198 - val_loss: 0.8545 - val_accuracy: 0.6431\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5412 - accuracy: 0.6875 - val_loss: 1.0174 - val_accuracy: 0.6996\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5084 - accuracy: 0.7177 - val_loss: 1.6122 - val_accuracy: 0.7601\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4764 - accuracy: 0.7480 - val_loss: 1.8073 - val_accuracy: 0.7661\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6119 - accuracy: 0.7137 - val_loss: 1.5770 - val_accuracy: 0.7339\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5462 - accuracy: 0.6794 - val_loss: 2.7405 - val_accuracy: 0.6815\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5274 - accuracy: 0.6976 - val_loss: 2.8122 - val_accuracy: 0.6815\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5125 - accuracy: 0.7077 - val_loss: 2.8197 - val_accuracy: 0.6815\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5253 - accuracy: 0.6976 - val_loss: 2.8224 - val_accuracy: 0.6815\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.5087 - accuracy: 0.7157 - val_loss: 3.8072 - val_accuracy: 0.7218\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5516 - accuracy: 0.7238 - val_loss: 2.2899 - val_accuracy: 0.6532\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5565 - accuracy: 0.6653 - val_loss: 2.7992 - val_accuracy: 0.6734\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5155 - accuracy: 0.7077 - val_loss: 3.8258 - val_accuracy: 0.7117\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.5035 - accuracy: 0.7198 - val_loss: 3.9336 - val_accuracy: 0.7157\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5172 - accuracy: 0.7077 - val_loss: 3.9366 - val_accuracy: 0.7157\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.4974 - accuracy: 0.7278 - val_loss: 5.7448 - val_accuracy: 0.7137\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.9460 - accuracy: 0.6210 - val_loss: 0.7290 - val_accuracy: 0.5202\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6631 - accuracy: 0.5444 - val_loss: 0.6875 - val_accuracy: 0.5222\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6446 - accuracy: 0.5544 - val_loss: 0.6811 - val_accuracy: 0.5222\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.6390 - accuracy: 0.5605 - val_loss: 0.6800 - val_accuracy: 0.5222\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6532 - accuracy: 0.5504 - val_loss: 0.6797 - val_accuracy: 0.5222\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6506 - accuracy: 0.5504 - val_loss: 0.6796 - val_accuracy: 0.5222\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6385 - accuracy: 0.5665 - val_loss: 0.6797 - val_accuracy: 0.5222\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6496 - accuracy: 0.5484 - val_loss: 0.6796 - val_accuracy: 0.5222\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6389 - accuracy: 0.5645 - val_loss: 0.6796 - val_accuracy: 0.5222\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6449 - accuracy: 0.5565 - val_loss: 0.6796 - val_accuracy: 0.5222\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6430 - accuracy: 0.5605 - val_loss: 0.6899 - val_accuracy: 0.5222\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6472 - accuracy: 0.5585 - val_loss: 0.6902 - val_accuracy: 0.5222\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6374 - accuracy: 0.5665 - val_loss: 0.6907 - val_accuracy: 0.5222\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6408 - accuracy: 0.5605 - val_loss: 0.6904 - val_accuracy: 0.5222\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6438 - accuracy: 0.5544 - val_loss: 0.6900 - val_accuracy: 0.5222\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6449 - accuracy: 0.5544 - val_loss: 0.6901 - val_accuracy: 0.5222\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6348 - accuracy: 0.5645 - val_loss: 0.6900 - val_accuracy: 0.5222\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6446 - accuracy: 0.5585 - val_loss: 0.6902 - val_accuracy: 0.5222\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.6518 - accuracy: 0.5524 - val_loss: 0.6901 - val_accuracy: 0.5222\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6518 - accuracy: 0.5544 - val_loss: 0.6904 - val_accuracy: 0.5222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6481 - accuracy: 0.5484 - val_loss: 0.6900 - val_accuracy: 0.5222\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6375 - accuracy: 0.5645 - val_loss: 0.6902 - val_accuracy: 0.5222\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6465 - accuracy: 0.5544 - val_loss: 0.6899 - val_accuracy: 0.5222\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6471 - accuracy: 0.5544 - val_loss: 0.6906 - val_accuracy: 0.5222\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.6474 - accuracy: 0.5544 - val_loss: 0.6901 - val_accuracy: 0.5222\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6442 - accuracy: 0.5605 - val_loss: 0.6900 - val_accuracy: 0.5222\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.6434 - accuracy: 0.5585 - val_loss: 0.6902 - val_accuracy: 0.5222\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6421 - accuracy: 0.5585 - val_loss: 0.6901 - val_accuracy: 0.5222\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.6425 - accuracy: 0.5585 - val_loss: 0.6899 - val_accuracy: 0.5222\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.6474 - accuracy: 0.5544 - val_loss: 0.6901 - val_accuracy: 0.5222\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.6489 - accuracy: 0.5544 - val_loss: 0.6902 - val_accuracy: 0.5222\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6422 - accuracy: 0.5565 - val_loss: 0.6903 - val_accuracy: 0.5222\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6405 - accuracy: 0.5605 - val_loss: 0.6900 - val_accuracy: 0.5222\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.6480 - accuracy: 0.5504 - val_loss: 0.6902 - val_accuracy: 0.5222\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6492 - accuracy: 0.5524 - val_loss: 0.6902 - val_accuracy: 0.5222\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6409 - accuracy: 0.5585 - val_loss: 0.6900 - val_accuracy: 0.5222\n",
      "16/16 [==============================] - 0s 6ms/step - loss: 0.6900 - accuracy: 0.5222\n",
      "Learning rate:  0.01  | Loss : 0.6899752616882324  | Accuracy : 0.5221773982048035\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 2s 21ms/step - loss: 4.2616 - accuracy: 0.5847 - val_loss: 0.7337 - val_accuracy: 0.5645\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.6342 - accuracy: 0.5484 - val_loss: 0.6426 - val_accuracy: 0.5565\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5913 - accuracy: 0.5685 - val_loss: 0.6799 - val_accuracy: 0.7117\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5747 - accuracy: 0.6452 - val_loss: 0.5599 - val_accuracy: 0.7681\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6271 - accuracy: 0.6048 - val_loss: 0.6110 - val_accuracy: 0.5081\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5796 - accuracy: 0.6734 - val_loss: 0.6075 - val_accuracy: 0.7077\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5739 - accuracy: 0.6915 - val_loss: 0.6172 - val_accuracy: 0.6855\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.6004 - accuracy: 0.6875 - val_loss: 0.6279 - val_accuracy: 0.7036\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5476 - accuracy: 0.6956 - val_loss: 0.6092 - val_accuracy: 0.7016\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.5253 - accuracy: 0.7097 - val_loss: 0.6311 - val_accuracy: 0.7218\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.5124 - accuracy: 0.7298 - val_loss: 0.6327 - val_accuracy: 0.7399\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.4998 - accuracy: 0.7480 - val_loss: 0.6675 - val_accuracy: 0.7722\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4974 - accuracy: 0.7742 - val_loss: 0.6950 - val_accuracy: 0.7339\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4803 - accuracy: 0.7601 - val_loss: 0.7919 - val_accuracy: 0.7903\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4459 - accuracy: 0.7823 - val_loss: 0.6289 - val_accuracy: 0.7621\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4556 - accuracy: 0.7742 - val_loss: 0.6478 - val_accuracy: 0.7399\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 12ms/step - loss: 0.4435 - accuracy: 0.7863 - val_loss: 0.7278 - val_accuracy: 0.7802\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4551 - accuracy: 0.7722 - val_loss: 0.7258 - val_accuracy: 0.7238\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4416 - accuracy: 0.7883 - val_loss: 0.8539 - val_accuracy: 0.7339\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4327 - accuracy: 0.7883 - val_loss: 0.7224 - val_accuracy: 0.7823\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4838 - accuracy: 0.7560 - val_loss: 0.6531 - val_accuracy: 0.7540\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4613 - accuracy: 0.7641 - val_loss: 0.6204 - val_accuracy: 0.7419\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.4367 - accuracy: 0.7863 - val_loss: 0.9252 - val_accuracy: 0.7560\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4416 - accuracy: 0.7984 - val_loss: 0.6659 - val_accuracy: 0.7540\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4668 - accuracy: 0.7782 - val_loss: 0.6593 - val_accuracy: 0.7742\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4851 - accuracy: 0.7581 - val_loss: 0.6392 - val_accuracy: 0.7359\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.4293 - accuracy: 0.7903 - val_loss: 0.7427 - val_accuracy: 0.7480\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4307 - accuracy: 0.7923 - val_loss: 0.6388 - val_accuracy: 0.7157\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4249 - accuracy: 0.7944 - val_loss: 0.9004 - val_accuracy: 0.7722\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3847 - accuracy: 0.8286 - val_loss: 0.9741 - val_accuracy: 0.7762\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3850 - accuracy: 0.8367 - val_loss: 0.9051 - val_accuracy: 0.7681\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4179 - accuracy: 0.7984 - val_loss: 0.8379 - val_accuracy: 0.7782\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.3993 - accuracy: 0.8105 - val_loss: 0.8784 - val_accuracy: 0.7762\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.3586 - accuracy: 0.8448 - val_loss: 0.8747 - val_accuracy: 0.7702\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3993 - accuracy: 0.8145 - val_loss: 0.7942 - val_accuracy: 0.7319\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.4056 - accuracy: 0.8206 - val_loss: 0.8831 - val_accuracy: 0.7500\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4112 - accuracy: 0.8044 - val_loss: 0.8529 - val_accuracy: 0.7560\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3887 - accuracy: 0.8206 - val_loss: 0.9103 - val_accuracy: 0.7702\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3993 - accuracy: 0.8266 - val_loss: 1.1515 - val_accuracy: 0.7802\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3875 - accuracy: 0.8347 - val_loss: 0.9116 - val_accuracy: 0.7742\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3895 - accuracy: 0.8286 - val_loss: 0.8147 - val_accuracy: 0.7480\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.3857 - accuracy: 0.8306 - val_loss: 0.7984 - val_accuracy: 0.7379\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3516 - accuracy: 0.8448 - val_loss: 1.0320 - val_accuracy: 0.7742\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3783 - accuracy: 0.8246 - val_loss: 0.8912 - val_accuracy: 0.7621\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3577 - accuracy: 0.8427 - val_loss: 0.9626 - val_accuracy: 0.7762\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3381 - accuracy: 0.8569 - val_loss: 1.0849 - val_accuracy: 0.7883\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3349 - accuracy: 0.8649 - val_loss: 0.9979 - val_accuracy: 0.7802\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3533 - accuracy: 0.8569 - val_loss: 1.0780 - val_accuracy: 0.7823\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3754 - accuracy: 0.8387 - val_loss: 1.1261 - val_accuracy: 0.7460\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3908 - accuracy: 0.8427 - val_loss: 0.8824 - val_accuracy: 0.7601\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3934 - accuracy: 0.8145 - val_loss: 1.9538 - val_accuracy: 0.7419\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4197 - accuracy: 0.8306 - val_loss: 1.1531 - val_accuracy: 0.7802\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3461 - accuracy: 0.8528 - val_loss: 1.5749 - val_accuracy: 0.7923\n",
      "Epoch 54/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.3313 - accuracy: 0.8629 - val_loss: 1.4402 - val_accuracy: 0.7863\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3612 - accuracy: 0.8528 - val_loss: 0.8727 - val_accuracy: 0.7440\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3307 - accuracy: 0.8710 - val_loss: 1.1996 - val_accuracy: 0.8004\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3625 - accuracy: 0.8629 - val_loss: 0.9266 - val_accuracy: 0.7782\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3662 - accuracy: 0.8367 - val_loss: 0.8587 - val_accuracy: 0.7641\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.3316 - accuracy: 0.8609 - val_loss: 1.3021 - val_accuracy: 0.7944\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3317 - accuracy: 0.8609 - val_loss: 1.1543 - val_accuracy: 0.7742\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3098 - accuracy: 0.8750 - val_loss: 1.1280 - val_accuracy: 0.7702\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3428 - accuracy: 0.8528 - val_loss: 1.2697 - val_accuracy: 0.7722\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3427 - accuracy: 0.8569 - val_loss: 1.2838 - val_accuracy: 0.7702\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.3278 - accuracy: 0.8649 - val_loss: 1.1443 - val_accuracy: 0.7742\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.2980 - accuracy: 0.8831 - val_loss: 1.2399 - val_accuracy: 0.7944\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.3122 - accuracy: 0.8750 - val_loss: 1.4823 - val_accuracy: 0.8024\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.3041 - accuracy: 0.8790 - val_loss: 1.7794 - val_accuracy: 0.7903\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.3086 - accuracy: 0.8750 - val_loss: 1.4164 - val_accuracy: 0.7802\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3348 - accuracy: 0.8770 - val_loss: 1.2000 - val_accuracy: 0.7964\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3265 - accuracy: 0.8669 - val_loss: 0.9231 - val_accuracy: 0.7843\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.3179 - accuracy: 0.8710 - val_loss: 1.4335 - val_accuracy: 0.7923\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2774 - accuracy: 0.8952 - val_loss: 1.6162 - val_accuracy: 0.8024\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.2875 - accuracy: 0.8911 - val_loss: 1.8405 - val_accuracy: 0.7964\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.2937 - accuracy: 0.8851 - val_loss: 2.0052 - val_accuracy: 0.8004\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.2805 - accuracy: 0.8931 - val_loss: 1.8705 - val_accuracy: 0.8085\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2853 - accuracy: 0.8891 - val_loss: 2.0119 - val_accuracy: 0.7984\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2834 - accuracy: 0.8911 - val_loss: 2.0208 - val_accuracy: 0.7984\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3197 - accuracy: 0.8690 - val_loss: 1.5777 - val_accuracy: 0.8024\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.2977 - accuracy: 0.8831 - val_loss: 1.5581 - val_accuracy: 0.7944\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2957 - accuracy: 0.8831 - val_loss: 1.8887 - val_accuracy: 0.7923\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2774 - accuracy: 0.8972 - val_loss: 1.6568 - val_accuracy: 0.7944\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2758 - accuracy: 0.8952 - val_loss: 1.5573 - val_accuracy: 0.7863\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3260 - accuracy: 0.8750 - val_loss: 1.2566 - val_accuracy: 0.7944\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3043 - accuracy: 0.8871 - val_loss: 1.3641 - val_accuracy: 0.7843\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2636 - accuracy: 0.9032 - val_loss: 1.4726 - val_accuracy: 0.7823\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3035 - accuracy: 0.8790 - val_loss: 1.4939 - val_accuracy: 0.7742\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.2881 - accuracy: 0.8871 - val_loss: 1.8513 - val_accuracy: 0.7883\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2984 - accuracy: 0.8891 - val_loss: 1.7895 - val_accuracy: 0.7843\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2868 - accuracy: 0.8891 - val_loss: 1.5182 - val_accuracy: 0.7843\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3007 - accuracy: 0.8810 - val_loss: 1.9244 - val_accuracy: 0.7903\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2930 - accuracy: 0.8851 - val_loss: 2.0807 - val_accuracy: 0.7984\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3029 - accuracy: 0.8831 - val_loss: 1.3029 - val_accuracy: 0.7903\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.2582 - accuracy: 0.9052 - val_loss: 1.4520 - val_accuracy: 0.7923\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.2589 - accuracy: 0.9052 - val_loss: 1.5498 - val_accuracy: 0.7883\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.2929 - accuracy: 0.8851 - val_loss: 1.2730 - val_accuracy: 0.7863\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2719 - accuracy: 0.8972 - val_loss: 1.3637 - val_accuracy: 0.7863\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - ETA: 0s - loss: 0.3388 - accuracy: 0.86 - 0s 8ms/step - loss: 0.3325 - accuracy: 0.8629 - val_loss: 1.4729 - val_accuracy: 0.7903\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 14ms/step - loss: 0.2814 - accuracy: 0.8911 - val_loss: 1.7017 - val_accuracy: 0.7843\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.3429 - accuracy: 0.8710 - val_loss: 1.1187 - val_accuracy: 0.7883\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2923 - accuracy: 0.8871 - val_loss: 1.5343 - val_accuracy: 0.7883\n",
      "16/16 [==============================] - 0s 4ms/step - loss: 1.5343 - accuracy: 0.7883\n",
      "Learning rate:  0.005  | Loss : 1.5342674255371094  | Accuracy : 0.788306474685669\n",
      "Epoch 1/100\n",
      "31/31 [==============================] - 1s 15ms/step - loss: 3.0806 - accuracy: 0.6472 - val_loss: 0.6697 - val_accuracy: 0.7258\n",
      "Epoch 2/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.5411 - accuracy: 0.7379 - val_loss: 0.6883 - val_accuracy: 0.7198\n",
      "Epoch 3/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.4205 - accuracy: 0.7944 - val_loss: 0.6364 - val_accuracy: 0.7681\n",
      "Epoch 4/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.3730 - accuracy: 0.8286 - val_loss: 0.6117 - val_accuracy: 0.7742\n",
      "Epoch 5/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2763 - accuracy: 0.8508 - val_loss: 0.6288 - val_accuracy: 0.8044\n",
      "Epoch 6/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.2573 - accuracy: 0.8851 - val_loss: 0.6756 - val_accuracy: 0.7782\n",
      "Epoch 7/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.2177 - accuracy: 0.8871 - val_loss: 0.7420 - val_accuracy: 0.7601\n",
      "Epoch 8/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.2092 - accuracy: 0.8911 - val_loss: 0.9037 - val_accuracy: 0.7883\n",
      "Epoch 9/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.2532 - accuracy: 0.8831 - val_loss: 0.7113 - val_accuracy: 0.8024\n",
      "Epoch 10/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1782 - accuracy: 0.8992 - val_loss: 0.7456 - val_accuracy: 0.7843\n",
      "Epoch 11/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1803 - accuracy: 0.8790 - val_loss: 0.6894 - val_accuracy: 0.7964\n",
      "Epoch 12/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1534 - accuracy: 0.9052 - val_loss: 0.7217 - val_accuracy: 0.7762\n",
      "Epoch 13/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1948 - accuracy: 0.8831 - val_loss: 0.8773 - val_accuracy: 0.7722\n",
      "Epoch 14/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2118 - accuracy: 0.8972 - val_loss: 0.7618 - val_accuracy: 0.8024\n",
      "Epoch 15/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.2094 - accuracy: 0.9012 - val_loss: 0.8407 - val_accuracy: 0.7964\n",
      "Epoch 16/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1490 - accuracy: 0.9133 - val_loss: 0.9400 - val_accuracy: 0.7863\n",
      "Epoch 17/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1876 - accuracy: 0.9073 - val_loss: 0.9333 - val_accuracy: 0.7863\n",
      "Epoch 18/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1518 - accuracy: 0.9052 - val_loss: 0.9461 - val_accuracy: 0.7944\n",
      "Epoch 19/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1481 - accuracy: 0.9173 - val_loss: 1.0779 - val_accuracy: 0.7984\n",
      "Epoch 20/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1657 - accuracy: 0.9073 - val_loss: 1.0162 - val_accuracy: 0.8004\n",
      "Epoch 21/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1490 - accuracy: 0.8891 - val_loss: 0.7474 - val_accuracy: 0.7923\n",
      "Epoch 22/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1189 - accuracy: 0.9194 - val_loss: 0.8998 - val_accuracy: 0.7984\n",
      "Epoch 23/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1610 - accuracy: 0.8810 - val_loss: 0.7573 - val_accuracy: 0.7964\n",
      "Epoch 24/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1296 - accuracy: 0.9073 - val_loss: 0.8488 - val_accuracy: 0.8024\n",
      "Epoch 25/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1130 - accuracy: 0.9274 - val_loss: 1.0651 - val_accuracy: 0.7944\n",
      "Epoch 26/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1424 - accuracy: 0.9254 - val_loss: 0.8153 - val_accuracy: 0.7843\n",
      "Epoch 27/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1497 - accuracy: 0.9294 - val_loss: 1.0034 - val_accuracy: 0.7823\n",
      "Epoch 28/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1353 - accuracy: 0.9536 - val_loss: 1.0452 - val_accuracy: 0.7903\n",
      "Epoch 29/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1281 - accuracy: 0.9274 - val_loss: 0.9494 - val_accuracy: 0.7903\n",
      "Epoch 30/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1426 - accuracy: 0.9173 - val_loss: 0.9269 - val_accuracy: 0.7782\n",
      "Epoch 31/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1481 - accuracy: 0.9355 - val_loss: 0.8464 - val_accuracy: 0.8004\n",
      "Epoch 32/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1186 - accuracy: 0.9375 - val_loss: 0.9912 - val_accuracy: 0.7984\n",
      "Epoch 33/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1145 - accuracy: 0.9415 - val_loss: 1.2214 - val_accuracy: 0.7903\n",
      "Epoch 34/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1172 - accuracy: 0.9516 - val_loss: 1.2495 - val_accuracy: 0.7964\n",
      "Epoch 35/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1424 - accuracy: 0.9294 - val_loss: 1.2884 - val_accuracy: 0.7762\n",
      "Epoch 36/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1186 - accuracy: 0.9234 - val_loss: 1.1079 - val_accuracy: 0.7984\n",
      "Epoch 37/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1188 - accuracy: 0.9335 - val_loss: 1.0500 - val_accuracy: 0.7823\n",
      "Epoch 38/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0835 - accuracy: 0.9496 - val_loss: 1.0860 - val_accuracy: 0.7903\n",
      "Epoch 39/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1142 - accuracy: 0.9657 - val_loss: 1.1052 - val_accuracy: 0.8004\n",
      "Epoch 40/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0985 - accuracy: 0.9335 - val_loss: 1.2779 - val_accuracy: 0.8004\n",
      "Epoch 41/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1353 - accuracy: 0.9456 - val_loss: 1.1425 - val_accuracy: 0.7823\n",
      "Epoch 42/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0856 - accuracy: 0.9556 - val_loss: 1.1567 - val_accuracy: 0.7802\n",
      "Epoch 43/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1254 - accuracy: 0.9375 - val_loss: 1.2567 - val_accuracy: 0.7762\n",
      "Epoch 44/100\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.1113 - accuracy: 0.9415 - val_loss: 1.2241 - val_accuracy: 0.7843\n",
      "Epoch 45/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.1006 - accuracy: 0.9415 - val_loss: 1.3436 - val_accuracy: 0.7823\n",
      "Epoch 46/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1044 - accuracy: 0.9435 - val_loss: 1.2539 - val_accuracy: 0.7964\n",
      "Epoch 47/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1034 - accuracy: 0.9496 - val_loss: 1.4702 - val_accuracy: 0.7944\n",
      "Epoch 48/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.1214 - accuracy: 0.9355 - val_loss: 1.1662 - val_accuracy: 0.7863\n",
      "Epoch 49/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0892 - accuracy: 0.9698 - val_loss: 1.2448 - val_accuracy: 0.7843\n",
      "Epoch 50/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0764 - accuracy: 0.9698 - val_loss: 1.3808 - val_accuracy: 0.7863\n",
      "Epoch 51/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1102 - accuracy: 0.9335 - val_loss: 1.4220 - val_accuracy: 0.7782\n",
      "Epoch 52/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0817 - accuracy: 0.9637 - val_loss: 1.3583 - val_accuracy: 0.7883\n",
      "Epoch 53/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0687 - accuracy: 0.9597 - val_loss: 1.4119 - val_accuracy: 0.7944\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0877 - accuracy: 0.9516 - val_loss: 1.4362 - val_accuracy: 0.7944\n",
      "Epoch 55/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0773 - accuracy: 0.9577 - val_loss: 1.5046 - val_accuracy: 0.7843\n",
      "Epoch 56/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.9556 - val_loss: 1.6681 - val_accuracy: 0.7923\n",
      "Epoch 57/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1036 - accuracy: 0.9516 - val_loss: 1.7419 - val_accuracy: 0.7923\n",
      "Epoch 58/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1085 - accuracy: 0.9395 - val_loss: 1.7737 - val_accuracy: 0.7762\n",
      "Epoch 59/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0871 - accuracy: 0.9476 - val_loss: 1.7180 - val_accuracy: 0.7883\n",
      "Epoch 60/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0786 - accuracy: 0.9617 - val_loss: 1.9107 - val_accuracy: 0.8004\n",
      "Epoch 61/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1288 - accuracy: 0.9335 - val_loss: 1.2368 - val_accuracy: 0.7843\n",
      "Epoch 62/100\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.0924 - accuracy: 0.9415 - val_loss: 1.5996 - val_accuracy: 0.7944\n",
      "Epoch 63/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0877 - accuracy: 0.9496 - val_loss: 1.8258 - val_accuracy: 0.7903\n",
      "Epoch 64/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.1185 - accuracy: 0.9415 - val_loss: 1.7337 - val_accuracy: 0.7782\n",
      "Epoch 65/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0894 - accuracy: 0.9456 - val_loss: 1.7404 - val_accuracy: 0.7762\n",
      "Epoch 66/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0850 - accuracy: 0.9556 - val_loss: 1.5860 - val_accuracy: 0.7722\n",
      "Epoch 67/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0828 - accuracy: 0.9456 - val_loss: 1.8346 - val_accuracy: 0.7722\n",
      "Epoch 68/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0623 - accuracy: 0.9577 - val_loss: 1.8057 - val_accuracy: 0.7823\n",
      "Epoch 69/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0635 - accuracy: 0.9698 - val_loss: 1.6675 - val_accuracy: 0.7762\n",
      "Epoch 70/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0768 - accuracy: 0.9577 - val_loss: 1.7938 - val_accuracy: 0.7762\n",
      "Epoch 71/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1141 - accuracy: 0.9496 - val_loss: 1.6949 - val_accuracy: 0.7843\n",
      "Epoch 72/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0939 - accuracy: 0.9536 - val_loss: 1.3146 - val_accuracy: 0.7802\n",
      "Epoch 73/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0784 - accuracy: 0.9556 - val_loss: 1.5522 - val_accuracy: 0.7762\n",
      "Epoch 74/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1080 - accuracy: 0.9435 - val_loss: 1.5528 - val_accuracy: 0.7722\n",
      "Epoch 75/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0773 - accuracy: 0.9556 - val_loss: 1.3893 - val_accuracy: 0.7702\n",
      "Epoch 76/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0744 - accuracy: 0.9536 - val_loss: 1.4840 - val_accuracy: 0.7843\n",
      "Epoch 77/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0661 - accuracy: 0.9577 - val_loss: 1.7520 - val_accuracy: 0.7802\n",
      "Epoch 78/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.1023 - accuracy: 0.9577 - val_loss: 1.6444 - val_accuracy: 0.8024\n",
      "Epoch 79/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0831 - accuracy: 0.9435 - val_loss: 1.6491 - val_accuracy: 0.7964\n",
      "Epoch 80/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0717 - accuracy: 0.9617 - val_loss: 1.7229 - val_accuracy: 0.7823\n",
      "Epoch 81/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0710 - accuracy: 0.9556 - val_loss: 1.8867 - val_accuracy: 0.7802\n",
      "Epoch 82/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0982 - accuracy: 0.9476 - val_loss: 1.8097 - val_accuracy: 0.7883\n",
      "Epoch 83/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0629 - accuracy: 0.9677 - val_loss: 2.0580 - val_accuracy: 0.7883\n",
      "Epoch 84/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0635 - accuracy: 0.9698 - val_loss: 1.9008 - val_accuracy: 0.7903\n",
      "Epoch 85/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0882 - accuracy: 0.9536 - val_loss: 1.6409 - val_accuracy: 0.7923\n",
      "Epoch 86/100\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.0677 - accuracy: 0.9617 - val_loss: 1.8544 - val_accuracy: 0.7843\n",
      "Epoch 87/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0755 - accuracy: 0.9516 - val_loss: 1.8504 - val_accuracy: 0.7823\n",
      "Epoch 88/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0780 - accuracy: 0.9516 - val_loss: 1.7890 - val_accuracy: 0.7802\n",
      "Epoch 89/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0946 - accuracy: 0.9516 - val_loss: 1.5188 - val_accuracy: 0.7944\n",
      "Epoch 90/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0661 - accuracy: 0.9698 - val_loss: 1.7065 - val_accuracy: 0.7944\n",
      "Epoch 91/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0560 - accuracy: 0.9738 - val_loss: 2.0312 - val_accuracy: 0.7964\n",
      "Epoch 92/100\n",
      "31/31 [==============================] - 0s 11ms/step - loss: 0.0855 - accuracy: 0.9577 - val_loss: 1.9668 - val_accuracy: 0.7863\n",
      "Epoch 93/100\n",
      "31/31 [==============================] - 0s 10ms/step - loss: 0.1090 - accuracy: 0.9637 - val_loss: 1.7636 - val_accuracy: 0.7843\n",
      "Epoch 94/100\n",
      "31/31 [==============================] - 0s 9ms/step - loss: 0.0808 - accuracy: 0.9435 - val_loss: 1.6903 - val_accuracy: 0.7903\n",
      "Epoch 95/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0689 - accuracy: 0.9597 - val_loss: 1.8856 - val_accuracy: 0.7883\n",
      "Epoch 96/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0520 - accuracy: 0.9698 - val_loss: 2.1093 - val_accuracy: 0.7923\n",
      "Epoch 97/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0622 - accuracy: 0.9637 - val_loss: 2.2562 - val_accuracy: 0.7863\n",
      "Epoch 98/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0711 - accuracy: 0.9617 - val_loss: 2.3355 - val_accuracy: 0.7964\n",
      "Epoch 99/100\n",
      "31/31 [==============================] - 0s 7ms/step - loss: 0.0468 - accuracy: 0.9657 - val_loss: 2.3370 - val_accuracy: 0.7823\n",
      "Epoch 100/100\n",
      "31/31 [==============================] - 0s 8ms/step - loss: 0.0819 - accuracy: 0.9738 - val_loss: 2.5372 - val_accuracy: 0.7923\n",
      "16/16 [==============================] - 0s 5ms/step - loss: 2.5372 - accuracy: 0.7923\n",
      "Learning rate:  0.001  | Loss : 2.537247896194458  | Accuracy : 0.7923387289047241\n"
     ]
    }
   ],
   "source": [
    "for lr in learning_rate:\n",
    "    train_data = np.load(open('bottleneck_features_train_2', 'rb'))\n",
    "\n",
    "    train_labels = np.array([0] * 248 + [1] * 248)\n",
    "\n",
    "    validation_data = np.load(open('bottleneck_features_validation_2', 'rb'))\n",
    "    validation_labels = np.array([0] * 248 + [1] * 248)\n",
    "\n",
    "    model = keras.Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=100,\n",
    "              batch_size=16,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "\n",
    "    loss, acc = model.evaluate(validation_data, validation_labels)\n",
    "    print('Learning rate: ', lr, ' | Loss :', loss,' | Accuracy :', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "grateful-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the output above\n",
    "# Learning rate:  0.1  | Loss : 0.6912845373153687  | Accuracy : 0.5\n",
    "# Learning rate:  0.05  | Loss : 0.6520873308181763  | Accuracy : 0.5766128897666931\n",
    "# Learning rate:  0.01  | Loss : 0.6899752616882324  | Accuracy : 0.5221773982048035\n",
    "# Learning rate:  0.005  | Loss : 1.5342674255371094  | Accuracy : 0.788306474685669\n",
    "# Learning rate:  0.001  | Loss : 2.537247896194458  | Accuracy : 0.7923387289047241"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lesbian-venezuela",
   "metadata": {},
   "source": [
    "We can see that default learning rate (0.001) turned out to be the best one among chosen ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applicable-parish",
   "metadata": {},
   "source": [
    "### II.III PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "abstract-subject",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2ec36020d10>"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "equipped-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory with photos\n",
    "root_dir = \"hotdog__not_hotdog_2/\" # less data chosen due to computation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "moved-klein",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming images\n",
    "image_transforms = {\n",
    "    \"train\": transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()]),\n",
    "    \"test\": transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "suffering-review",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data\n",
    "hotdog_dataset = datasets.ImageFolder(root = root_dir + \"train\", transform = image_transforms[\"train\"])\n",
    "hotdog_dataset_size = len(hotdog_dataset)\n",
    "hotdog_dataset_indices = list(range(hotdog_dataset_size))\n",
    "np.random.shuffle(hotdog_dataset_indices)\n",
    "# val data\n",
    "val_split_index = int(np.floor(0.2 * hotdog_dataset_size))\n",
    "train_idx, val_idx = hotdog_dataset_indices[val_split_index:], hotdog_dataset_indices[:val_split_index]\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(val_idx)\n",
    "# test data\n",
    "hotdog_dataset_test = datasets.ImageFolder(root = root_dir + \"test\", transform = image_transforms[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "scenic-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "train_loader = DataLoader(dataset=hotdog_dataset, shuffle=False, batch_size=8, sampler=train_sampler)\n",
    "val_loader = DataLoader(dataset=hotdog_dataset, shuffle=False, batch_size=1, sampler=val_sampler)\n",
    "test_loader = DataLoader(dataset=hotdog_dataset_test, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "balanced-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class HotDogClassifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HotDogClassifier, self).__init__()\n",
    "        self.block1 = self.conv_block(c_in=3, c_out=256, dropout=0.1, kernel_size=5, stride=1, padding=2)\n",
    "        self.block2 = self.conv_block(c_in=256, c_out=128, dropout=0.1, kernel_size=3, stride=1, padding=1)\n",
    "        self.block3 = self.conv_block(c_in=128, c_out=64, dropout=0.1, kernel_size=3, stride=1, padding=1)\n",
    "        self.lastcnn = nn.Conv2d(in_channels=64, out_channels=2, kernel_size=56, stride=1, padding=0)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.lastcnn(x)\n",
    "        return x\n",
    "    \n",
    "    def conv_block(self, c_in, c_out, dropout,  **kwargs):\n",
    "        seq_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c_in, out_channels=c_out, **kwargs),\n",
    "            nn.BatchNorm2d(num_features=c_out),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout2d(p=dropout)\n",
    "        )\n",
    "        return seq_block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "alleged-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiation, loss function and optimizer\n",
    "model = HotDogClassifier()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "concerned-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "def binary_acc(y_pred, y_test):\n",
    "    y_pred_tag = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_tag, dim = 1)\n",
    "    correct_results_sum = (y_pred_tags == y_test).sum().float()\n",
    "    acc = correct_results_sum/y_test.shape[0]\n",
    "    acc = torch.round(acc * 100)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "cleared-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrays for results\n",
    "accuracy_stats = {'train': [], \"val\": []}\n",
    "loss_stats = {'train': [], \"val\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "negative-discrimination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e784554087242f3a056ffc335e04e0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: | Train Loss: 10.27189 | Val Loss: 33.40048 | Train Acc: 76.950| Val Acc: 45.000\n",
      "Epoch 02: | Train Loss: 6.61747 | Val Loss: 32.90903 | Train Acc: 78.850| Val Acc: 37.500\n",
      "Epoch 03: | Train Loss: 4.84312 | Val Loss: 26.05276 | Train Acc: 82.050| Val Acc: 62.500\n",
      "Epoch 04: | Train Loss: 3.75801 | Val Loss: 21.33476 | Train Acc: 83.750| Val Acc: 47.500\n",
      "Epoch 05: | Train Loss: 1.98939 | Val Loss: 20.99336 | Train Acc: 88.350| Val Acc: 45.000\n",
      "Epoch 06: | Train Loss: 2.96364 | Val Loss: 31.79333 | Train Acc: 87.750| Val Acc: 55.000\n",
      "Epoch 07: | Train Loss: 0.60493 | Val Loss: 28.48789 | Train Acc: 97.600| Val Acc: 40.000\n",
      "Epoch 08: | Train Loss: 0.96445 | Val Loss: 45.95710 | Train Acc: 92.050| Val Acc: 40.000\n",
      "Epoch 09: | Train Loss: 3.64730 | Val Loss: 40.30748 | Train Acc: 82.650| Val Acc: 45.000\n",
      "Epoch 10: | Train Loss: 2.81778 | Val Loss: 38.68331 | Train Acc: 90.700| Val Acc: 50.000\n",
      "Epoch 11: | Train Loss: 1.38353 | Val Loss: 37.58377 | Train Acc: 93.950| Val Acc: 55.000\n",
      "Epoch 12: | Train Loss: 1.56968 | Val Loss: 40.03315 | Train Acc: 93.950| Val Acc: 40.000\n",
      "Epoch 13: | Train Loss: 0.49734 | Val Loss: 38.50595 | Train Acc: 97.600| Val Acc: 50.000\n",
      "Epoch 14: | Train Loss: 0.86049 | Val Loss: 44.67650 | Train Acc: 95.050| Val Acc: 45.000\n",
      "Epoch 15: | Train Loss: 0.77575 | Val Loss: 33.97760 | Train Acc: 95.750| Val Acc: 47.500\n",
      "Epoch 16: | Train Loss: 1.61820 | Val Loss: 43.52767 | Train Acc: 93.850| Val Acc: 52.500\n",
      "Epoch 17: | Train Loss: 0.70749 | Val Loss: 52.71809 | Train Acc: 97.000| Val Acc: 45.000\n",
      "Epoch 18: | Train Loss: 1.58850 | Val Loss: 48.59669 | Train Acc: 93.950| Val Acc: 47.500\n",
      "Epoch 19: | Train Loss: 3.14012 | Val Loss: 55.91518 | Train Acc: 90.650| Val Acc: 47.500\n",
      "Epoch 20: | Train Loss: 0.15093 | Val Loss: 42.97055 | Train Acc: 98.200| Val Acc: 42.500\n"
     ]
    }
   ],
   "source": [
    "for e in tqdm(range(1, 21)):\n",
    "    \n",
    "    # training\n",
    "    train_epoch_loss = 0\n",
    "    train_epoch_acc = 0\n",
    "    model.train()\n",
    "    for X_train_batch, y_train_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_train_pred = model(X_train_batch).squeeze()\n",
    "        train_loss = criterion(y_train_pred, y_train_batch)\n",
    "        train_acc = binary_acc(y_train_pred, y_train_batch)\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_epoch_loss += train_loss.item()\n",
    "        train_epoch_acc += train_acc.item()\n",
    "        \n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_epoch_loss = 0\n",
    "        val_epoch_acc = 0\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            y_val_pred = model(X_val_batch).squeeze()\n",
    "            y_val_pred = torch.unsqueeze(y_val_pred, 0)\n",
    "            val_loss = criterion(y_val_pred, y_val_batch)\n",
    "            val_acc = binary_acc(y_val_pred, y_val_batch)\n",
    "            val_epoch_loss += val_loss.item()\n",
    "            val_epoch_acc += val_acc.item()\n",
    "    # results        \n",
    "    loss_stats['train'].append(train_epoch_loss/len(train_loader))\n",
    "    loss_stats['val'].append(val_epoch_loss/len(val_loader))\n",
    "    accuracy_stats['train'].append(train_epoch_acc/len(train_loader))\n",
    "    accuracy_stats['val'].append(val_epoch_acc/len(val_loader))\n",
    "    print(f'Epoch {e+0:02}: | Train Loss: {train_epoch_loss/len(train_loader):.5f} | Val Loss: {val_epoch_loss/len(val_loader):.5f} | Train Acc: {train_epoch_acc/len(train_loader):.3f}| Val Acc: {val_epoch_acc/len(val_loader):.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "unusual-encoding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2f7f502d3e4f6eb8cc80d36fa7bc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test set\n",
    "y_pred_list = []\n",
    "y_true_list = []\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in tqdm(test_loader):\n",
    "        y_test_pred = model(x_batch)\n",
    "        _, y_pred_tag = torch.max(y_test_pred, dim = 1)\n",
    "        y_pred_list.append(y_pred_tag.cpu().numpy())\n",
    "        y_true_list.append(y_batch.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "bulgarian-czech",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_list = [i[0][0][0] for i in y_pred_list]\n",
    "y_true_list = [i[0] for i in y_true_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "double-experiment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.41      0.46       250\n",
      "           1       0.51      0.62      0.56       250\n",
      "\n",
      "    accuracy                           0.52       500\n",
      "   macro avg       0.52      0.52      0.51       500\n",
      "weighted avg       0.52      0.52      0.51       500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true_list, y_pred_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-trunk",
   "metadata": {},
   "source": [
    "The results aren't really good, probably due to few epochs and smaller train set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
